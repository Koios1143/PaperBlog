export const pagesRoutes = [
  ["v-8daa1a0e","/",{"y":"h","t":"Blog Home","i":"home"},["/README.md"]],
  ["v-184f4da6","/intro.html",{"d":1704067200000,"l":"January 1, 2024","e":"<h1> About us</h1>\n","y":"a","t":"About us","i":"circle-info"},[":md"]],
  ["v-3caeec67","/posts/Agent57.html",{"a":"Koios","d":1708732800000,"l":"February 24, 2024","c":["Note"],"g":["Paper Read","Reinforcement Learning","ICML"],"e":"<h1> Agent57: Outperforming the Atari Human Benchmark</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>Adrià Puigdomènech Badia, Bilal Piot, Steven Kapturowski, et al. @ Google DeepMind</li>\n<li>2020 ICML</li>\n</ul>\n<h2> 問題描述</h2>\n<p>在 RL 當中，Atari games 是一個相當重要的 benchmark。過去的 RL 模型已經能夠在大多的 atari games 當中獲得相當不錯的 performance，例如 MuZero、R2D2，分別在 57 個遊戲當中有 51 和 52 個遊戲是 outperform 人類的。不過可惜的是，在剩下的遊戲當中這些 SoTA 就通常完全沒辦法學習。</p>","y":"a","t":"Agent57: Outperforming the Atari Human Benchmark"},[":md"]],
  ["v-50ae5da2","/posts/AlexNet.html",{"a":"Xavier","d":1710288000000,"l":"March 13, 2024","c":["Note"],"g":["Paper Read","Supervised Learning","Convolutional Neural Networks","Computer Vision"],"e":"<h1> AlexNet: ImageNet Classifications with Deep Convolutional Neural Networks</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton @ University of Toronto</li>\n<li>2012 NeurlIPS</li>\n</ul>\n<h2> 問題描述</h2>\n<p>這是一篇將Deep Learning(深度學習)與Convolutional Neural Networks(卷積神經網路，以下簡稱CNN)運用在Computer Vision(計算機視覺)領域的開拓性論文。作者們train了一個Deep Convolutional Neural Network來分類ImageNet LSVRC-2010資料集中的120萬張高解析度圖像，並得到了相較前人方法顯著優異許多的表現。</p>","y":"a","t":"AlexNet: ImageNet Classifications with Deep Convolutional Neural Networks"},[":md"]],
  ["v-c0336012","/posts/DACS.html",{"a":"Koios","d":1705708800000,"l":"January 20, 2024","c":["Note"],"g":["Paper Read","Domain Adaption","Computer Vision","WACV"],"e":"<h1> DACS: Domain Adaptation via Cross-domain Mixed Sampling</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>2020 Release</li>\n<li>2021 WACV(Winter Conference on Applications of Computer Vision)</li>\n<li>Chalmers University of Technology(查爾摩斯理工大學)與 Volvo Cars 共同發表</li>\n</ul>\n<h2> What is Domain Adaption</h2>","y":"a","t":"DACS: Domain Adaptation via Cross-domain Mixed Sampling"},[":md"]],
  ["v-6fdb6976","/posts/DAFormer.html",{"a":"Koios","d":1710115200000,"l":"March 11, 2024","c":["Note"],"g":["Paper Read","Domain Adaption","Computer Vision","CVPR"],"e":"<h1> DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>Lukas Hoyer, Dengxin Dai, Luc Van Gool @ ETH Zurich &amp; MPI for Informatics</li>\n<li>2022 CVPR</li>\n</ul>\n\n<br>\n<blockquote>\n<p>Image from <a href=\"https://arxiv.org/abs/2111.14887\" target=\"_blank\" rel=\"noopener noreferrer\">Lukas Hoyer, Dengxin Dai, Luc Van Gool (2022)</a></p>\n</blockquote>","y":"a","t":"DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation"},[":md"]],
  ["v-32d63a0d","/posts/DQN.html",{"a":"Koios","d":1707436800000,"l":"February 9, 2024","c":["Note"],"g":["Paper Read","Reinforcement Learning","NeurIPS"],"e":"<h1> Playing Atari with Deep Reinforcement Learning</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>2013 NeurIPS</li>\n<li>Volodymyr Mnih, Koray Kavukcuoglu David Silver et al.</li>\n<li>這個論文提出的做法稱為 DQN(Deep Q-Networks)</li>\n</ul>\n<h2> 問題描述</h2>\n<p>過去在 RL 領域當中把一些 high-dimensional 的感官資料（如：視覺影像、語音資料等）作為 agent 的輸入去學習一直是一個很大的挑戰。然而我們也看到近幾年 Deep Learning 已經能夠在這種資料上去擷取特徵，進而去完成許多複雜的任務。</p>","y":"a","t":"Playing Atari with Deep Reinforcement Learning"},[":md"]],
  ["v-073f61cf","/posts/Dropout.html",{"a":"Koios","d":1710633600000,"l":"March 17, 2024","c":["Note"],"g":["Paper Read","Regularization","JMLR"],"e":"<h1> Dropout: A Simple Way to Prevent Neural Networks from Overfitting</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov @ Toronto University</li>\n<li>2014 JMLR</li>\n</ul>\n<h2> 問題描述</h2>\n<p>在近年來發現到 Neural Network 參數越多就有越強大的表達能力，並且通常會有更好的表現。不過隨著參數量的上升，我們也發現到模型越來越會傾向於 Overfitting。</p>","y":"a","t":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting"},[":md"]],
  ["v-25c9f246","/posts/HRDA.html",{"a":"Koios","d":1710547200000,"l":"March 16, 2024","c":["Note"],"g":["Paper Read","Domain Adaption","Computer Vision","ECCV"],"e":"<h1> HRDA: Context-Aware High-Resolution Domain-Adaptive Semantic Segmentation</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>Lukas Hoyer, Dengxin Dai, Luc Van Gool @ ETH Zurich &amp; MPI for Informatics</li>\n<li>2022 ECCV</li>\n</ul>\n<h2> 問題描述</h2>\n<p>這篇 paper 如同 DAFormer 關注在 UDA for semantic segmentation 。</p>","y":"a","t":"HRDA: Context-Aware High-Resolution Domain-Adaptive Semantic Segmentation"},[":md"]],
  ["v-5b18c8c4","/posts/Noisy%20Networks%20for%20Exploration.html",{"a":"Koios","d":1706918400000,"l":"February 3, 2024","c":["Note"],"g":["Paper Read","Reinforcement Learning","ICLR"],"e":"<h1> Noisy Networks for Exploration</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>2018 ICLR</li>\n<li>Meire Fortunato, Mohammad Gheshlaghi Azar, Bilal Piot, et al. @ Google Deepmind</li>\n</ul>\n<h2> 問題描述</h2>\n<p>在過去的 RL 當中我們往往仰賴對 agent 的 policy 增加 randomness 去增加 exploration，例如 <code>ϵ-greedy</code> 和 <code>entropy regularization</code> 等。不過這樣的做法往往只能在較於簡單的環境當中有比較有效率的探索，然而在現實狀況下往往並不會如此簡單，而這種探索的困難度甚至是指數性地成長。</p>","y":"a","t":"Noisy Networks for Exploration"},["/posts/Noisy Networks for Exploration.html","/posts/Noisy Networks for Exploration.md",":md"]],
  ["v-0fd9e004","/posts/ProDA.html",{"a":"Koios","d":1710115200000,"l":"March 11, 2024","c":["Note"],"g":["Paper Read","Domain Adaption","Computer Vision","CVPR"],"e":"<h1> Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation</h1>\n<h2> Basic Information</h2>\n<ul>\n<li>Pan Zhang1, Bo Zhang, Ting Zhang, Dong Chen, Yong Wang, Fang Wen @ University of Science and Technology of China, Microsoft Research Asia</li>\n<li>2021 CVPR</li>\n</ul>","y":"a","t":"Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation"},[":md"]],
  ["v-3706649a","/404.html",{"y":"p","t":""},[]],
  ["v-e1e3da16","/posts/",{"y":"p","t":"Posts"},[]],
  ["v-5bc93818","/category/",{"y":"p","t":"Category","I":false},[]],
  ["v-744d024e","/tag/",{"y":"p","t":"Tag","I":false},[]],
  ["v-e52c881c","/article/",{"y":"p","t":"Articles","I":false},[]],
  ["v-154dc4c4","/star/",{"y":"p","t":"Star","I":false},[]],
  ["v-01560935","/timeline/",{"y":"p","t":"Timeline","I":false},[]],
  ["v-58706565","/category/note/",{"y":"p","t":"Note Category","I":false},[]],
  ["v-1724726c","/tag/paper-read/",{"y":"p","t":"Tag: Paper Read","I":false},[]],
  ["v-7f7459b2","/tag/reinforcement-learning/",{"y":"p","t":"Tag: Reinforcement Learning","I":false},[]],
  ["v-28948988","/tag/icml/",{"y":"p","t":"Tag: ICML","I":false},[]],
  ["v-5ab697b6","/tag/supervised-learning/",{"y":"p","t":"Tag: Supervised Learning","I":false},[]],
  ["v-79b786d4","/tag/convolutional-neural-networks/",{"y":"p","t":"Tag: Convolutional Neural Networks","I":false},[]],
  ["v-cc78423a","/tag/computer-vision/",{"y":"p","t":"Tag: Computer Vision","I":false},[]],
  ["v-65da17ce","/tag/domain-adaption/",{"y":"p","t":"Tag: Domain Adaption","I":false},[]],
  ["v-2958c584","/tag/wacv/",{"y":"p","t":"Tag: WACV","I":false},[]],
  ["v-2848ab8c","/tag/cvpr/",{"y":"p","t":"Tag: CVPR","I":false},[]],
  ["v-468b3b36","/tag/neurips/",{"y":"p","t":"Tag: NeurIPS","I":false},[]],
  ["v-2554e3d9","/tag/regularization/",{"y":"p","t":"Tag: Regularization","I":false},[]],
  ["v-28a729b8","/tag/jmlr/",{"y":"p","t":"Tag: JMLR","I":false},[]],
  ["v-285c0730","/tag/eccv/",{"y":"p","t":"Tag: ECCV","I":false},[]],
  ["v-28948681","/tag/iclr/",{"y":"p","t":"Tag: ICLR","I":false},[]],
]
