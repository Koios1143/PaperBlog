const nt="ENTRIES",V="KEYS",T="VALUES",F="";class D{set;_type;_path;constructor(t,s){const n=t._tree,u=Array.from(n.keys());this.set=t,this._type=s,this._path=u.length>0?[{node:n,keys:u}]:[]}next(){const t=this.dive();return this.backtrack(),t}dive(){if(this._path.length===0)return{done:!0,value:void 0};const{node:t,keys:s}=E(this._path);if(E(s)===F)return{done:!1,value:this.result()};const n=t.get(E(s));return this._path.push({node:n,keys:Array.from(n.keys())}),this.dive()}backtrack(){if(this._path.length===0)return;const t=E(this._path).keys;t.pop(),!(t.length>0)&&(this._path.pop(),this.backtrack())}key(){return this.set._prefix+this._path.map(({keys:t})=>E(t)).filter(t=>t!==F).join("")}value(){return E(this._path).node.get(F)}result(){switch(this._type){case T:return this.value();case V:return this.key();default:return[this.key(),this.value()]}}[Symbol.iterator](){return this}}const E=e=>e[e.length-1],ut=(e,t,s)=>{const n=new Map;if(t===void 0)return n;const u=t.length+1,o=u+s,i=new Uint8Array(o*u).fill(s+1);for(let r=0;r<u;++r)i[r]=r;for(let r=1;r<o;++r)i[r*u]=r;return R(e,t,s,n,i,1,u,""),n},R=(e,t,s,n,u,o,i,r)=>{const d=o*i;t:for(const l of e.keys())if(l===F){const a=u[d-1];a<=s&&n.set(r,[e.get(l),a])}else{let a=o;for(let h=0;h<l.length;++h,++a){const m=l[h],p=i*a,f=p-i;let c=u[p];const g=Math.max(0,a-s-1),_=Math.min(i-1,a+s);for(let y=g;y<_;++y){const b=m!==t[y],z=u[f+y]+ +b,A=u[f+y+1]+1,w=u[p+y]+1,L=u[p+y+1]=Math.min(z,A,w);L<c&&(c=L)}if(c>s)continue t}R(e.get(l),t,s,n,u,a,i,r+l)}};class C{_tree;_prefix;_size=void 0;constructor(t=new Map,s=""){this._tree=t,this._prefix=s}atPrefix(t){if(!t.startsWith(this._prefix))throw new Error("Mismatched prefix");const[s,n]=x(this._tree,t.slice(this._prefix.length));if(s===void 0){const[u,o]=M(n);for(const i of u.keys())if(i!==F&&i.startsWith(o)){const r=new Map;return r.set(i.slice(o.length),u.get(i)),new C(r,t)}}return new C(s,t)}clear(){this._size=void 0,this._tree.clear()}delete(t){return this._size=void 0,ot(this._tree,t)}entries(){return new D(this,nt)}forEach(t){for(const[s,n]of this)t(s,n,this)}fuzzyGet(t,s){return ut(this._tree,t,s)}get(t){const s=I(this._tree,t);return s!==void 0?s.get(F):void 0}has(t){const s=I(this._tree,t);return s!==void 0&&s.has(F)}keys(){return new D(this,V)}set(t,s){if(typeof t!="string")throw new Error("key must be a string");return this._size=void 0,O(this._tree,t).set(F,s),this}get size(){if(this._size)return this._size;this._size=0;const t=this.entries();for(;!t.next().done;)this._size+=1;return this._size}update(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=O(this._tree,t);return n.set(F,s(n.get(F))),this}fetch(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=O(this._tree,t);let u=n.get(F);return u===void 0&&n.set(F,u=s()),u}values(){return new D(this,T)}[Symbol.iterator](){return this.entries()}static from(t){const s=new C;for(const[n,u]of t)s.set(n,u);return s}static fromObject(t){return C.from(Object.entries(t))}}const x=(e,t,s=[])=>{if(t.length===0||e==null)return[e,s];for(const n of e.keys())if(n!==F&&t.startsWith(n))return s.push([e,n]),x(e.get(n),t.slice(n.length),s);return s.push([e,t]),x(void 0,"",s)},I=(e,t)=>{if(t.length===0||e==null)return e;for(const s of e.keys())if(s!==F&&t.startsWith(s))return I(e.get(s),t.slice(s.length))},O=(e,t)=>{const s=t.length;t:for(let n=0;e&&n<s;){for(const o of e.keys())if(o!==F&&t[n]===o[0]){const i=Math.min(s-n,o.length);let r=1;for(;r<i&&t[n+r]===o[r];)++r;const d=e.get(o);if(r===o.length)e=d;else{const l=new Map;l.set(o.slice(r),d),e.set(t.slice(n,n+r),l),e.delete(o),e=l}n+=r;continue t}const u=new Map;return e.set(t.slice(n),u),u}return e},ot=(e,t)=>{const[s,n]=x(e,t);if(s!==void 0){if(s.delete(F),s.size===0)W(n);else if(s.size===1){const[u,o]=s.entries().next().value;q(n,u,o)}}},W=e=>{if(e.length===0)return;const[t,s]=M(e);if(t.delete(s),t.size===0)W(e.slice(0,-1));else if(t.size===1){const[n,u]=t.entries().next().value;n!==F&&q(e.slice(0,-1),n,u)}},q=(e,t,s)=>{if(e.length===0)return;const[n,u]=M(e);n.set(u+t,s),n.delete(u)},M=e=>e[e.length-1],it=(e,t)=>{const s=e._idToShortId.get(t);if(s!=null)return e._storedFields.get(s)},rt=/[\n\r -#%-*,-/:;?@[-\]_{}\u00A0\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u1680\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2000-\u200A\u2010-\u2029\u202F-\u2043\u2045-\u2051\u2053-\u205F\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u3000-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]+/u,S="or",$="and",ct="and_not",lt=(e,t)=>{e.includes(t)||e.push(t)},P=(e,t)=>{for(const s of t)e.includes(s)||e.push(s)},N=({score:e},{score:t})=>t-e,ht=()=>new Map,k=e=>{const t=new Map;for(const s of Object.keys(e))t.set(parseInt(s,10),e[s]);return t},G=(e,t)=>Object.prototype.hasOwnProperty.call(e,t)?e[t]:void 0,dt={[S]:(e,t)=>{for(const s of t.keys()){const n=e.get(s);if(n==null)e.set(s,t.get(s));else{const{score:u,terms:o,match:i}=t.get(s);n.score=n.score+u,n.match=Object.assign(n.match,i),P(n.terms,o)}}return e},[$]:(e,t)=>{const s=new Map;for(const n of t.keys()){const u=e.get(n);if(u==null)continue;const{score:o,terms:i,match:r}=t.get(n);P(u.terms,i),s.set(n,{score:u.score+o,terms:u.terms,match:Object.assign(u.match,r)})}return s},[ct]:(e,t)=>{for(const s of t.keys())e.delete(s);return e}},at=(e,t,s,n,u,o)=>{const{k:i,b:r,d}=o;return Math.log(1+(s-t+.5)/(t+.5))*(d+e*(i+1)/(e+i*(1-r+r*n/u)))},ft=e=>(t,s,n)=>{const u=typeof e.fuzzy=="function"?e.fuzzy(t,s,n):e.fuzzy||!1,o=typeof e.prefix=="function"?e.prefix(t,s,n):e.prefix===!0;return{term:t,fuzzy:u,prefix:o}},H=(e,t,s,n)=>{for(const u of Object.keys(e._fieldIds))if(e._fieldIds[u]===s){e._options.logger("warn",`SlimSearch: document with ID ${e._documentIds.get(t)} has changed before removal: term "${n}" was not present in field "${u}". Removing a document after it has changed can corrupt the index!`,"version_conflict");return}},gt=(e,t,s,n)=>{if(!e._index.has(n)){H(e,s,t,n);return}const u=e._index.fetch(n,ht),o=u.get(t);o==null||o.get(s)==null?H(e,s,t,n):o.get(s)<=1?o.size<=1?u.delete(t):o.delete(s):o.set(s,o.get(s)-1),e._index.get(n).size===0&&e._index.delete(n)},mt={k:1.2,b:.7,d:.5},pt={idField:"id",extractField:(e,t)=>e[t],tokenize:e=>e.split(rt),processTerm:e=>e.toLowerCase(),fields:void 0,searchOptions:void 0,storeFields:[],logger:(e,t)=>{typeof console?.[e]=="function"&&console[e](t)},autoVacuum:!0},J={combineWith:S,prefix:!1,fuzzy:!1,maxFuzzy:6,boost:{},weights:{fuzzy:.45,prefix:.375},bm25:mt},Ft={combineWith:$,prefix:(e,t,s)=>t===s.length-1},_t={batchSize:1e3,batchWait:10},U={minDirtFactor:.1,minDirtCount:20},yt={..._t,...U},Y=(e,t=S)=>{if(e.length===0)return new Map;const s=t.toLowerCase();return e.reduce(dt[s])||new Map},B=(e,t,s,n,u,o,i,r,d=new Map)=>{if(u==null)return d;for(const l of Object.keys(o)){const a=o[l],h=e._fieldIds[l],m=u.get(h);if(m==null)continue;let p=m.size;const f=e._avgFieldLength[h];for(const c of m.keys()){if(!e._documentIds.has(c)){gt(e,h,c,s),p-=1;continue}const g=i?i(e._documentIds.get(c),s,e._storedFields.get(c)):1;if(!g)continue;const _=m.get(c),y=e._fieldLength.get(c)[h],b=at(_,p,e._documentCount,y,f,r),z=n*a*g*b,A=d.get(c);if(A){A.score+=z,lt(A.terms,t);const w=G(A.match,s);w?w.push(l):A.match[s]=[l]}else d.set(c,{score:z,terms:[t],match:{[s]:[l]}})}}return d},At=(e,t,s)=>{const n={...e._options.searchOptions,...s},u=(n.fields||e._options.fields).reduce((c,g)=>({...c,[g]:G(n.boost,g)||1}),{}),{boostDocument:o,weights:i,maxFuzzy:r,bm25:d}=n,{fuzzy:l,prefix:a}={...J.weights,...i},h=e._index.get(t.term),m=B(e,t.term,t.term,1,h,u,o,d);let p,f;if(t.prefix&&(p=e._index.atPrefix(t.term)),t.fuzzy){const c=t.fuzzy===!0?.2:t.fuzzy,g=c<1?Math.min(r,Math.round(t.term.length*c)):c;g&&(f=e._index.fuzzyGet(t.term,g))}if(p)for(const[c,g]of p){const _=c.length-t.term.length;if(!_)continue;f?.delete(c);const y=a*c.length/(c.length+.3*_);B(e,t.term,c,y,g,u,o,d,m)}if(f)for(const c of f.keys()){const[g,_]=f.get(c);if(!_)continue;const y=l*c.length/(c.length+_);B(e,t.term,c,y,g,u,o,d,m)}return m},X=(e,t,s={})=>{if(typeof t!="string"){const a={...s,...t,queries:void 0},h=t.queries.map(m=>X(e,m,a));return Y(h,a.combineWith)}const{tokenize:n,processTerm:u,searchOptions:o}=e._options,i={tokenize:n,processTerm:u,...o,...s},{tokenize:r,processTerm:d}=i,l=r(t).flatMap(a=>d(a)).filter(a=>!!a).map(ft(i)).map(a=>At(e,a,i));return Y(l,i.combineWith)},K=(e,t,s={})=>{const n=X(e,t,s),u=[];for(const[o,{score:i,terms:r,match:d}]of n){const l=r.length,a={id:e._documentIds.get(o),score:i*l,terms:Object.keys(d),match:d};Object.assign(a,e._storedFields.get(o)),(s.filter==null||s.filter(a))&&u.push(a)}return u.sort(N),u},Ct=(e,t,s={})=>{s={...e._options.autoSuggestOptions,...s};const n=new Map;for(const{score:o,terms:i}of K(e,t,s)){const r=i.join(" "),d=n.get(r);d!=null?(d.score+=o,d.count+=1):n.set(r,{score:o,terms:i,count:1})}const u=[];for(const[o,{score:i,terms:r,count:d}]of n)u.push({suggestion:o,terms:r,score:i/d});return u.sort(N),u};class Et{_options;_index;_documentCount;_documentIds;_idToShortId;_fieldIds;_fieldLength;_avgFieldLength;_nextId;_storedFields;_dirtCount;_currentVacuum;_enqueuedVacuum;_enqueuedVacuumConditions;constructor(t){if(t?.fields==null)throw new Error('SlimSearch: option "fields" must be provided');const s=t.autoVacuum==null||t.autoVacuum===!0?yt:t.autoVacuum;this._options={...pt,...t,autoVacuum:s,searchOptions:{...J,...t.searchOptions||{}},autoSuggestOptions:{...Ft,...t.autoSuggestOptions||{}}},this._index=new C,this._documentCount=0,this._documentIds=new Map,this._idToShortId=new Map,this._fieldIds={},this._fieldLength=new Map,this._avgFieldLength=[],this._nextId=0,this._storedFields=new Map,this._dirtCount=0,this._currentVacuum=null,this._enqueuedVacuum=null,this._enqueuedVacuumConditions=U,this.addFields(this._options.fields)}get isVacuuming(){return this._currentVacuum!=null}get dirtCount(){return this._dirtCount}get dirtFactor(){return this._dirtCount/(1+this._documentCount+this._dirtCount)}get documentCount(){return this._documentCount}get termCount(){return this._index.size}toJSON(){const t=[];for(const[s,n]of this._index){const u={};for(const[o,i]of n)u[o]=Object.fromEntries(i);t.push([s,u])}return{documentCount:this._documentCount,nextId:this._nextId,documentIds:Object.fromEntries(this._documentIds),fieldIds:this._fieldIds,fieldLength:Object.fromEntries(this._fieldLength),averageFieldLength:this._avgFieldLength,storedFields:Object.fromEntries(this._storedFields),dirtCount:this._dirtCount,index:t,serializationVersion:2}}addFields(t){for(let s=0;s<t.length;s++)this._fieldIds[t[s]]=s}}const zt=({index:e,documentCount:t,nextId:s,documentIds:n,fieldIds:u,fieldLength:o,averageFieldLength:i,storedFields:r,dirtCount:d,serializationVersion:l},a)=>{if(l!==1&&l!==2)throw new Error("SlimSearch: cannot deserialize an index created with an incompatible version");const h=new Et(a);h._documentCount=t,h._nextId=s,h._documentIds=k(n),h._idToShortId=new Map,h._fieldIds=u,h._fieldLength=k(o),h._avgFieldLength=i,h._storedFields=k(r),h._dirtCount=d||0,h._index=new C;for(const[m,p]of h._documentIds)h._idToShortId.set(p,m);for(const[m,p]of e){const f=new Map;for(const c of Object.keys(p)){let g=p[c];l===1&&(g=g.ds),f.set(parseInt(c,10),k(g))}h._index.set(m,f)}return h},Q=Object.entries,wt=Object.fromEntries,j=(e,t)=>{const s=e.toLowerCase(),n=t.toLowerCase(),u=[];let o=0,i=0;const r=(l,a=!1)=>{let h="";i===0?h=l.length>20?`… ${l.slice(-20)}`:l:a?h=l.length+i>100?`${l.slice(0,100-i)}… `:l:h=l.length>20?`${l.slice(0,20)} … ${l.slice(-20)}`:l,h&&u.push(h),i+=h.length,a||(u.push(["mark",t]),i+=t.length,i>=100&&u.push(" …"))};let d=s.indexOf(n,o);if(d===-1)return null;for(;d>=0;){const l=d+n.length;if(r(e.slice(o,d)),o=l,i>100)break;d=s.indexOf(n,o)}return i<100&&r(e.slice(o),!0),u},Z=/[\u4e00-\u9fa5]/g,tt=(e={})=>({fuzzy:.2,prefix:!0,processTerm:t=>{const s=t.match(Z)||[],n=t.replace(Z,"").toLowerCase();return n?[n,...s]:[...s]},...e}),xt=(e,t)=>t.contents.reduce((s,[,n])=>s+n,0)-e.contents.reduce((s,[,n])=>s+n,0),kt=(e,t)=>Math.max(...t.contents.map(([,s])=>s))-Math.max(...e.contents.map(([,s])=>s)),et=(e,t,s={})=>{const n={};return K(t,e,tt({boost:{h:2,t:1,c:4},...s})).forEach(u=>{const{id:o,terms:i,score:r}=u,d=o.includes("@"),l=o.includes("#"),[a,h]=o.split(/[#@]/),m=i.sort((f,c)=>f.length-c.length).filter((f,c)=>i.slice(c+1).every(g=>!g.includes(f))),{contents:p}=n[a]??={title:"",contents:[]};if(d)p.push([{type:"customField",key:a,index:h,display:m.map(f=>u.c.map(c=>j(c,f))).flat().filter(f=>f!==null)},r]);else{const f=m.map(c=>j(u.h,c)).filter(c=>c!==null);if(f.length&&p.push([{type:l?"heading":"title",key:a,...l&&{anchor:h},display:f},r]),"t"in u)for(const c of u.t){const g=m.map(_=>j(c,_)).filter(_=>_!==null);g.length&&p.push([{type:"text",key:a,...l&&{anchor:h},display:g},r])}}}),Q(n).sort(([,u],[,o])=>"max"==="total"?xt(u,o):kt(u,o)).map(([u,{title:o,contents:i}])=>{if(!o){const r=it(t,u);r&&(o=r.h)}return{title:o,contents:i.map(([r])=>r)}})},st=(e,t,s={})=>Ct(t,e,tt(s)).map(({suggestion:n})=>n),v=wt(Q(JSON.parse("{\"/\":{\"documentCount\":62,\"nextId\":62,\"documentIds\":{\"0\":\"v-184f4da6\",\"1\":\"v-184f4da6#skills\",\"2\":\"v-184f4da6#競賽成績\",\"3\":\"v-184f4da6#活動參與\",\"4\":\"v-620a6165\",\"5\":\"v-620a6165#比賽題目\",\"6\":\"v-620a6165#比賽過程\",\"7\":\"v-620a6165#datasets-處理\",\"8\":\"v-620a6165#答案產出\",\"9\":\"v-620a6165#結果\",\"10\":\"v-620a6165#報告\",\"11\":\"v-620a6165#總結\",\"12\":\"v-620a6165@0\",\"13\":\"v-620a6165@1\",\"14\":\"v-c0336012\",\"15\":\"v-c0336012#basic-information\",\"16\":\"v-c0336012#what-is-domain-adaption\",\"17\":\"v-c0336012#問題描述\",\"18\":\"v-c0336012#related-works\",\"19\":\"v-c0336012#domain-alignment\",\"20\":\"v-c0336012#pseudo-labelling-or-self-training\",\"21\":\"v-c0336012#mixing\",\"22\":\"v-c0336012#methodology\",\"23\":\"v-c0336012#naive-mixing-to-uda\",\"24\":\"v-c0336012#domain-adaption-via-corss-domain-mixed-sampling-dacs\",\"25\":\"v-c0336012#results\",\"26\":\"v-c0336012#實驗設定\",\"27\":\"v-c0336012#dataset\",\"28\":\"v-c0336012#cityscapes\",\"29\":\"v-c0336012#gta5\",\"30\":\"v-c0336012#synthia\",\"31\":\"v-c0336012#gta5-cityscapes\",\"32\":\"v-c0336012#synthia-cityscapes\",\"33\":\"v-c0336012#some-issues-about-evaluation\",\"34\":\"v-c0336012#contribution\",\"35\":\"v-c0336012#值得一看的文章們\",\"36\":\"v-c0336012@0\",\"37\":\"v-c0336012@1\",\"38\":\"v-6e6058d4\",\"39\":\"v-6e6058d4#第一場面試\",\"40\":\"v-6e6058d4#warnup\",\"41\":\"v-6e6058d4#題目敘述\",\"42\":\"v-6e6058d4#思路\",\"43\":\"v-6e6058d4#follow-up\",\"44\":\"v-6e6058d4#題目敘述-1\",\"45\":\"v-6e6058d4#思路-1\",\"46\":\"v-6e6058d4#第一場面試小結\",\"47\":\"v-6e6058d4#第二場面試\",\"48\":\"v-6e6058d4#warn-up\",\"49\":\"v-6e6058d4#題目敘述-2\",\"50\":\"v-6e6058d4#思路-2\",\"51\":\"v-6e6058d4#question-1\",\"52\":\"v-6e6058d4#思路-1-1\",\"53\":\"v-6e6058d4#思路-2-1\",\"54\":\"v-6e6058d4#question-1-follow-up\",\"55\":\"v-6e6058d4#思路-1-2\",\"56\":\"v-6e6058d4#思路-2-2\",\"57\":\"v-6e6058d4#第二場面試小結\",\"58\":\"v-6e6058d4#總結\",\"59\":\"v-6e6058d4@0\",\"60\":\"v-6e6058d4@1\",\"61\":\"v-e1e3da16\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[2,29],\"1\":[1,35],\"2\":[1,80],\"3\":[1,56],\"4\":[4,15],\"5\":[1,42],\"6\":[1,86],\"7\":[2,35],\"8\":[1,13],\"9\":[1,13],\"10\":[1,20],\"11\":[1,24],\"12\":[null,null,1],\"13\":[null,null,2],\"14\":[8],\"15\":[2,19],\"16\":[4,49],\"17\":[1,49],\"18\":[2],\"19\":[2,77],\"20\":[6,108],\"21\":[1,66],\"22\":[1],\"23\":[4,54],\"24\":[9,67],\"25\":[1],\"26\":[1,37],\"27\":[1,15],\"28\":[1,13],\"29\":[1,19],\"30\":[1,28],\"31\":[3,48],\"32\":[3,39],\"33\":[4,52],\"34\":[1,19],\"35\":[1,52],\"36\":[null,null,1],\"37\":[null,null,7],\"38\":[6,39],\"39\":[1],\"40\":[1],\"41\":[1,15],\"42\":[1,84],\"43\":[2],\"44\":[1,14],\"45\":[1,24],\"46\":[1,16],\"47\":[1,3],\"48\":[2],\"49\":[1,2],\"50\":[1,11],\"51\":[2,22],\"52\":[2,19],\"53\":[2,96],\"54\":[4,8],\"55\":[2,17],\"56\":[2,42],\"57\":[1,4],\"58\":[1,26],\"59\":[null,null,1],\"60\":[null,null,2],\"61\":[1]},\"averageFieldLength\":[1.986495858898811,37.076475781313015,0.4491556760754345],\"storedFields\":{\"0\":{\"h\":\"About Me\",\"t\":[\"本名林禾堃，一個喜愛資訊領域的人。目前就讀於清華大學資訊工程學系，過去曾擔任臺南一中資訊社社長，也是 SCIST 的共同創辦人之一。\",\"高中接觸了演算法、資訊安全、網路管理等領域，目前正在朝向 Deep Learning 領域發展，關注的主題包含 Computer Vision、Reinforcement Learning 以及 Large Language Model。\",\"希望透過這個 blog 紀錄學習的點滴，也歡迎一起來討論 ML 領域的各種知識！\"]},\"1\":{\"h\":\"Skills\",\"t\":[\"Programming Languagues\",\"C/C++, Python, JavaScripts\",\"Frameworks\",\"React, Hexo, LINE BOT, PyTorch\",\"Machine Learning\",\"Computer Vision, Reinforcement Learning\",\"Miscellaneous\",\"UNIX Programming, Cryptography, Reverse engineering, Git, Markdown, Vim\",\"Languages\",\"Mandarin (Native), English (TOEFL 81), Japanese (JLPT N1)\"]},\"2\":{\"h\":\"競賽成績\",\"t\":[\"日期\",\"競賽名稱\",\"成績\",\"心得\",\"2024年01月\",\"2024 TSMC CareerHack\",\"無\",\"心得\",\"2022年10月\",\"梅竹黑客松\",\"分組第三名\",\"2022年07月\",\"YTP Final Project\",\"專題第三名\",\"2020年07月\",\"青年黑克松\",\"網頁組第3名\",\"2020年06月\",\"AIS3 pre-exam\",\"第96名\",\"2020年06月\",\"MyFirstCTF\",\"第22名\",\"2020年04月\",\"Google Code Jam Qualification Round\",\"第29755名(30/100分)\",\"2020年03月\",\"Kick Start Round A 2020\",\"第5695名(21/100分)\",\"2020年03月\",\"TOI初選\",\"第62名(212/500分)\",\"2020年02月\",\"TOI校內賽\",\"第7名(314/600分)\",\"2020年01月\",\"TOI海選\",\"300/300分\",\"2019年12月\",\"NPSC決賽\",\"全國第六名\",\"2019年11月\",\"金盾獎\",\"進入決賽\",\"2019年10月\",\"Kick Start Round G 2019\",\"第2427名(10/100分)\",\"2019年07月\",\"FML-based Machine Learning Competition for Human\",\"世界第三名\",\"2019年06月\",\"第七屆高一生程式設計排名賽\",\"128/800\"]},\"3\":{\"h\":\"活動參與\",\"t\":[\"日期\",\"活動\",\"心得/筆記\",\"2023年04月-\",\"機器學習讀書會 成員\",\"2022年10月-\",\"日語學習小組 成員\",\"2023年09月\",\"NTHU CS Camp 講師\",\"2022年07月\",\"IONCamp 營長\",\"2022年\",\"資訊之芽 C 班講師\",\"2022年08月\",\"索拉教育 Python 課程講師\",\"2022年07月\",\"索拉教育 C++ 課程講師\",\"2020年09月\",\"AIS3 CLUB\",\"2020年08月\",\"奧義科技參訪\",\"2020年08月\",\"SITCON 2020\",\"2020年07月\",\"AIS3 2020\",\"2020年07月\",\"2020 ISIP SummerCamp\",\"筆記\",\"2020年-2021年\",\"SCIST\",\"2020年01月\",\"IOICamp\",\"2019年11月\",\"臺灣好厲駭 Machine Learning & Security\",\"筆記\",\"2019年08月\",\"HITCON 2019\",\"2019年08月\",\"HITCON HackDoor\",\"2019年07月\",\"2019 My FirstSecurity Summer Camp\",\"2019年07月\",\"第八屆成功大學大學生活體驗營\",\"2019年03月\",\"SITCON 2019\"]},\"4\":{\"h\":\"2024 TSMC CareerHack 心得\",\"t\":[\"前幾天去參加了 2024 台積電的黑客松，大概是人生第一次走進台積辦公室。\",\"這場比賽是一組四人的比賽，前面有一個預賽，需要解出一些簡單的演算法題目。每個人題目會不太相同，但基本上都不會太難，簡單的 Sort、Greedy、Graph、DP。\"]},\"5\":{\"h\":\"比賽題目\",\"t\":[\"我們這一組拿到的是 AI 看圖說故事 的題目，基本上就是會有一些工地的照片，希望我們可以去找到\",\"照片中有多少人\",\"有多少人有戴安全帽\",\"有多少人沒戴安全帽\",\"安全帽是甚麼顏色\",\"有些圖片上面會有 warning message，所以會有額外的提問\",\"warning message 寫了什麼\",\"有沒有任何人違反了 warning message 的敘述\",\"基本上他們期待我們會運用 LLM 去解決這個問題，TSMC 也有先提供了一些資源\",\"GCP 運算及儲存資源 \",\"L4 GPU (24 GB RAM) x2\",\"100 GB CPU RAM\",\"100 GB Disk\",\"100 GB Bucket storage\",\"LLaVA pretrained model\",\"LLaVA finetune script\",\"一些 Datasets\"]},\"6\":{\"h\":\"比賽過程\",\"t\":[\"比賽會在正式開賽前一周公布題目，也開放資源，因此不少組別在實際進到 HackDay 前就已經做了不少，也有聽說有部分的組別 HackDay 就是拿來做簡報，也是頗有趣。\",\"雖然說是黑客松，不過場地因為是辦公室，所以晚上 6 點就要回家，隔天早上 9 點半再來報到，實際上在辦公室的時間沒有想像中的還要多。\",\"一開始進去到辦公室的感覺就很舒服，可以自己使用的免費咖啡機、電動的升降桌、超級舒服的人體工學椅、超大的雙螢幕。\",\"只能說在設備上直接贏了。\",\"中間還有提供午餐、點心、飲料，都相當地好吃，覺得很開心。\",\"我們這一組在 HackDay 之前的想法是先去做一些 paper research，去調查看看有哪些其他還不錯的 LLM 可以嘗試。\",\"雖然說在比賽之前我們的想法是，如果只會問那些固定的問題的話，那我們不要用 LLM，用其他 CV 的 model 去解決也許會比 LLM 還要強許多，不過寄信去詢問之後得到希望還是使用到 LLM 的回覆，所以我們後續的方向都著重在 LLM 以及 Fine-tune 的研究。\",\"大致上大家看過了幾個 LLM\",\"miniGPT4、miniGPT4_v2\",\"BLIP、InstructBLIP\",\"Flamingo\",\"Fine-tune 的部分主要是參考各個 paper 自己的 fine-tune 說明，其他的大概就是 proxy-tuning。\",\"其實讀 paper 都覺得很好理解，也想說難得有不錯的運算資源，是也可以都 train 看看結果如何。不過理想很美好，現實很骨感。\",\"實際上我們挑了最小的 13B 模型，丟進去訓練還是出現 CUDA out of memory，估計也是沒救，最後只有 LLaVA 活下來，所以我們後續就主要專攻 LLaVA。\"]},\"7\":{\"h\":\"Datasets 處理\",\"t\":[\"我們在 Dataset 處理上花了不少的時間。\",\"在提供的 5 份 datasets 當中，我們發現其中兩份都是教室的監視器錄影畫面，我們想說這裡根本沒人戴安全帽，超級懷疑這個 dataset 的實用程度。\",\"此外，其他的 dataset 也是有些包含浮水印，或是看起來安全帽是後製貼上去的，彩度跟亮度跟環境有些落差。\",\"我們也發現到說在回答顏色的那一題，模型會傾向回答 None，但實際上有顏色才對，所以在前面加上了一些 prefix string，試圖讓 LLM 吐出更多結果。\",\"實驗上為了檢測拿掉兩個 datasets 以及加上 prefix string 是否有比較好，交叉做了一些 fintune，也寫了一個評分程式去評估好壞。\"]},\"8\":{\"h\":\"答案產出\",\"t\":[\"我們最後決定要把多個模型的輸出拿去做類似 Bagging 的操作。\",\"簡單來說，這七個問題，我們相信那些回答分數比較高的模型可以做得比較好，所以就讓他專門來回答這個問題。\",\"如此一來就可以得到完整的輸出結果，也可以盡可能至少在 validation set 上看起來很棒 ouo\"]},\"9\":{\"h\":\"結果\",\"t\":[\"最後在 private set 上的分數大概是 59.7\",\"加權分數: 44.5/70\",\"Bonus: 2.7/5\",\"其實不太好啦XD\"]},\"10\":{\"h\":\"報告\",\"t\":[\"其實 TSMC 的大家都很友善，報告期間也都會跟我們分享他們覺得在每個地方有哪些比較好的做法也許可以嘗試看看。\",\"此外，其他組的報告我們也可以透過實時的直播去看，認識到其他組都用了怎樣的方法去解決。\",\"印象中有人用了 YOLO，也有人套了 OCR，把輸出結果套入 LLM 的輸入。有些組別完成度很高，甚至連 FrontEnd 都完成了，相當佩服。\"]},\"11\":{\"h\":\"總結\",\"t\":[\"我覺得這次到 TSMC 的比賽經驗很不錯，也讓我認識到 TSMC 的 IT team，跟過去自己想像當中在無塵室裏面處理晶圓的那種印象是完全不同，我也能感受到每個員工對我們都很友善。\",\"當時有遇到問題去找他們的時候都可以得到即時的 feedback，也能感受到他們對我們的提問的重視，是一個讓人很喜歡的環境。\",\"這次大概是第一次實際碰 LLM，過去基本上就是看過 paper，讀的時候都覺得嗯嗯嗯很有道理，不過實際上在實作的時候光是硬體的資源可能就是一大障礙，也就很難往下一步去發展。\",\"但總結來說這次有還蠻有趣的體驗，感到很開心，也很期待未來也還有機會可以繼續了解和開發 LLM。\"]},\"12\":{\"c\":[\"Feedbacks\"]},\"13\":{\"c\":[\"TSMC\",\"CareerHack\"]},\"14\":{\"h\":\"DACS: Domain Adaptation via Cross-domain Mixed Sampling\"},\"15\":{\"h\":\"Basic Information\",\"t\":[\"2020 Release\",\"2021 WACV(Winter Conference on Applications of Computer Vision)\",\"Chalmers University of Technology(查爾摩斯理工大學)與 Volvo Cars 共同發表\"]},\"16\":{\"h\":\"What is Domain Adaption\",\"t\":[\"Image from Medium\",\"所謂的 Domain 就是用來描述一群資料他們的分布狀況。\",\"Domain Adaption 的目標是把兩個不同分佈的 Domain (Source Domain 以及 Target Domain) 投射到同一個平面上，使得同類型的資料會相近，反之則相遠。\",\"舉一個在 CV 上的例子。如果我們想要訓練一個模型去做自駕車的街景物件偵測，很多時候我們並不會直接去蒐集真實的資料，像是直接有一台車會去蒐集真實街景資料，這樣所需要的成本會過大。時常我們會訓練在合成資料上(synethic data)，然後再應用在真實的世界當中。\",\"Image from Medium\",\"不過這種情況下一個直覺的問題是，在 虛擬世界(Source Domain) 上也許我們能夠對各種物件去做標記 label，但是對於真實世界(Target Domain)往往會有許多我們沒有的 label、環境與虛擬世界有差距，這種差距被描述為 Domain Shift。當兩個 Domain 相差過大，Domain Shift 過高，就會導致單純在 Source Domain 上訓練的模型難以直接 apply 到 Target Domain 上。\",\"因此，Domain Adaption 想解決的就是盡可能地將 Domain Shift 降低，讓我們得以用較低的成本在虛擬環境中訓練模型，然後應用在真實的環境當中。\"]},\"17\":{\"h\":\"問題描述\",\"t\":[\"近年來透過 CNN 處理 semantic segmentation(影像分割) 的模型雖然有許多，也獲得不錯的成果，不過如果遇到新的 domain，往往就會 work 不太好，尤其是從 synethic data 轉變到 real data 上的時候。\",\"問題在於不同的 domain，各自的 domain distribution 會不同。只訓練在 source domain 的模型對於 target domain 的狀況缺乏認知，導致預測失準。\",\"Info\",\"這就像是同理心，因為缺乏對他人的理解，擅自用自己的思維解讀，就會導致互相的不理解。\",\"Image from Liang-ChiehChen et al. (2015)\",\"可以發現單純用 CNN 就可以得到相當好的影像分割結果。\",\"Image from Yiheng Zhang et al. (2018)\",\"直接把訓練在虛擬環境的模型應用在真實環境，結果相當糟糕。\"]},\"18\":{\"h\":\"Related Works\"},\"19\":{\"h\":\"Domain Alignment\",\"t\":[\"透過 adversarial learning (對抗式學習) 去拉近 source domain 以及 target domain。\",\"我們可以想成現在 Segmentation Network 就是 GAN 的 Generator，然後會有一個 Discriminator 去判別現在給我的究竟是 source domain 還是 target domain 的預測結果。\",\"Image from Yi-Hsuan Tsai et al. (2018)\",\"兩個 Domain 中各取圖片，經過相同的 Segmentation Network，將產出的 semantic maps 做對抗式學習\",\"Info\",\"依照 alignment 的不同，可以分成 pixel level, feature map level, semantic level 等不同的做法。\",\"這樣的做法之所以可行，是源自於即便 domain 不同，在 semantic maps 上的 spatial layout 以及 local context 通常並不會差太多。\",\"DACS 的做法之所以能夠成功，也有部分是源自於這樣的相似性帶來的好處。\",\"Tips\",\"同樣以自駕車的例子來說，即便 synethic data 和 real data 的 domain 有相當大的差異，不過像是馬路、汽車、行人都還是會跟地板黏在一起，其他像是路燈、號誌、天空之類的就通常會像是在半空中。這類的 spatial layout 就相當地雷同。\",\"Image from Yi-Hsuan Tsai et al. (2018)\"]},\"20\":{\"h\":\"pseudo labelling (or self-training)\",\"t\":[\"Adversarial Learning for Semi-Supervised Semantic Segmentation\",\"最初是為了解決 半監督式學習(Semi-Supervise Learning, SSL) 而被提出的。\",\"Info\",\"所謂的半監督式學習也就是說 target domain 的資料上只有一些 labeled data，其他絕大多都是 unlabeled data，這種狀況下訓練模型就被稱為半監督式學習。\",\"而半監督式學習困難的點在於雖然對於 Target Domain 有部分的認知，但是並不全面。\",\"一個簡單的方法是想辦法給這些 unlabeled data 一些 pseudo label。那我們就可以用 supervise learning 的方法解決了。\",\"舉例來說，先在 labeled data 上訓練一個模型，透過這個模型我們就有辦法給 unlabeled data 做 prediction，而 prediction 的結果就當作是他的 pseudo label，就可以再拿去 fine-tune model 了。\",\"Image from Sylwia Majchrowska et al. (2021)\",\"但主要的問題來自於 Domain Shift，畢竟 Source Domain 和 Target Domain 還是存在差異的，並不是所有的 Target Data 都能夠透過 Source Data 去轉移出來。\",\"尤其在 Unsupervised Domain Adaption(UDA) 來說是相當大的問題，在 UDA 當中通常 Domain Shift 都會特別大。\",\"Info\",\"所謂的 UDA 也就是說我們對於 Target Domain 的資料不存在任何 label。換句話說，我們對於 Target Domain 缺乏 label 上的認知。\",\"對於 UDA 來說由於缺乏對於 Target Domain 的認識，一個常見的問題是產出的結果通常會傾向去預測結果為常見的 class。\",\"Info\",\"對陌生人的認識，往往先從貼標籤開始。\",\"例如說在自駕車的道路辨識當中鄰近人行道這種時常出現的 class，如果出現道路或甚至機車，有可能就被誤判成人行道。或是汽車比卡車更常見，導致卡車時常被預測成汽車。\",\"Image from Yang Zou et al (2018)\",\"看 column 4，只有 pseudo labeling 的例子\",\"Info\",\"雖然已經有 paper 提出如 CBST 的方法來降低這種問題，但在邊界上往往還是難以有好的結果。\"]},\"21\":{\"h\":\"Mixing\",\"t\":[\"Mixing 基本上就是從 training image 拿出兩張，透過一些方式混在一起，產生一個新的 training image。最初被用於把 unlabeled image 混合成新的圖片，是一種 data augumentation 的技巧。\",\"像是 Mixup 這種 data augumentation 方法也是屬於 Mixing 的一種。\",\"DACS 當中使用的是 ClassMix 這種 Mixing 方法。\",\"具體來說，ClassMix 的步驟\",\"把兩個圖片 (A,B) 先轉成 semantic map (SA​,SB​)\",\"把 SA​ 其中一半的 classes 對應的 semantic map 做出一個 binary mask (M)\",\"把 mask M apply 在 A 上，跟 B 合成出 XA​。\",\"把 mask M apply 在 SA​ 上，跟 SB​ 合成出 XA​ 對應的 semantic map YA​\",\"Image from Viktor Olsson et al. (2020)\",\"這樣的做法有趣的是能夠將 semantic segmentation 在邊界上往往會出現誤差的問題解決。\",\"邊界上的判斷會因為圖片跟相鄰環境的相似導致模糊不清。但透過剪貼則可以造成不同環境的突兀感，進而解決這個問題。因此這時候 pseudo labelling 就能夠比較好發揮作用。\",\"Image from Viktor Olsson et al. (2020)\"]},\"22\":{\"h\":\"Methodology\"},\"23\":{\"h\":\"Naive Mixing to UDA\",\"t\":[\"最 Naive 的做法就是照著 ClassMix 的方法，將 unlebelled dataset Mixing 成新的 dataset，把 labelled dataset 以及 mixed dataset 拿去訓練。\",\"Info\",\"在 UDA 當中，unlabelled dataset 就是 target domain dataset。\",\"Image from Wilhelm Tranheden at al.\",\"但是這種做法實際上效果很糟糕。像是 sidewalk 被預測成 road，rider 被預測成 person 之類的，許多的 class 都被其他 class 覆蓋。這樣的問題只在 target domain 上會發生，這跟前面提到只使用 pseudo labelling to UDA 會造成的問題是吻合的。\",\"Image from Wilhelm Tranheden at al.\",\"單純的 Naive Mixing 往往在邊界上會有許多誤判的 class\",\"Tips\",\"這種相似的 class 相鄰而導致的誤判被稱為 class conflation\"]},\"24\":{\"h\":\"Domain Adaption via Corss-domain mixed Sampling (DACS)\",\"t\":[\"DACS 的核心做法是不單只是跟 Target Domain 去 mixing，而是將 Source 跟 Target 一起 Mix。如此一來， Target Domain 以及 Source Domain 的關聯性就能被連結起來，降低 Domain Shift。\",\"Image from Wilhelm Tranheden at al.\",\"詳細的步驟具體來說\",\"從 Source Domain (DS​) 取出圖片與 lebel (XS​,YS​)\",\"從 Target Domain (DT​) 取出圖片 XT​\",\"透過 segmentation network fθ​ 取得 XT​ 的 pseudo label YT​^​\",\"將 (XS​,YS​),(XT​,YT​^​) 經過 ClassMix 得到 (XM​,YM​)\",\"把 (XS​,YS​),(XM​,YM​) 拿去訓練。\",\"Image from Wilhelm Tranheden at al.\",\"在 Loss 的設計上也相當直覺，就是希望 XS​ 的預測結果要接近 YS​，XM​ 的結果要接近 YM​。\",\"H: Cross-Entropy\",\"λ: 調整 Mixing 部分的影響程度\",\"L(θ)=E[H(fθ​(XS​),YS​)+λH(fθ​(XM​),YM​)]\"]},\"25\":{\"h\":\"Results\"},\"26\":{\"h\":\"實驗設定\",\"t\":[\"在 segmentation network 的設定上參考了許多過去的研究，選擇採用 DeepLab v2 搭配 ResNet101 作為 backbone。\",\"ResNet101 是 pretrained on ImageNet 跟 MSCOCO。而 Hyperparameter 的設定基本上跟 Yi-Hsuan Tsai et al. (2018) 一樣。\",\"在 Mixing 的方法上雖然任何 based on binary mask 的 Mixing 都可以使用，不過這裡最主要都是使用 ClassMix。\"]},\"27\":{\"h\":\"Dataset\",\"t\":[\"在 synthetic-to-real 有一些常見的 benchmarks。\",\"GTA5 -> Cityscapes\",\"SYNTHIA -> Cityscapes\",\"GTA5 以及 SYNTHIA 都是虛擬世界當中的影像，而 Cityscapes 則是現實世界當中的影像。\"]},\"28\":{\"h\":\"Cityscapes\",\"t\":[\"照片是在城市當中開車拍下的各種照片\",\"Image from Marius Cordts et al. (2016)\",\"2975 training images\",\"19 classes\"]},\"29\":{\"h\":\"GTA5\",\"t\":[\"照片是在 GTA5 下拍攝的\",\"Image from Stephan R. Richter et al.\",\"24966 synthetic training images\",\"19 classes \",\"可對應到 Cityscapes 的 classes\"]},\"30\":{\"h\":\"SYNTHIA\",\"t\":[\"照片是在 Unity 建構的 virtual city 下拍攝\",\"Image from GermanRos et al. (2016)\",\"9400 synthetic training images\",\"16(or 13) classes \",\"都會對到 Cityscapes 的 classes\",\"13 個 classes 的版本是少了 Wall, Fence, Pole\"]},\"31\":{\"h\":\"GTA5 -> Cityscapes\",\"t\":[\"Image from Wilhelm Tranheden at al.\",\"其他的 Model 都是 DeepLab-v2，他們選擇其中 Performance 最好的，但 Backbone 並不一定要是 ResNet 101\",\"Image from Wilhelm Tranheden at al.\",\"Source 是只有使用 source domain 去 train 的模型\",\"Info\",\"可以發現\",\"單純用 source domain 去訓練顯然很糟糕，只對簡單的 class 像是 Road, Build, Veg, Sky, Person, Car 這些普遍做得不錯的 class 有還不錯的 Performance\",\"DACS 在絕大多數並非是最佳的結果上都不會離最佳太遠，除了 SW 有點偏以及 Train 真的很糟\"]},\"32\":{\"h\":\"SYNTHIA -> Cityscapes\",\"t\":[\"考慮到 SYNTHIA 有些 paper 使用 16 個 classes，有些是 13 個 class 的版本，所以在數據上 mIoU 有兩列分別表示 13 個平均跟 16 個的平均。\",\"Image from Wilhelm Tranheden at al.\",\"Info\",\"可以發現\",\"單純用 source domain 去訓練顯然很糟糕，甚至對 Road 的 Performance 都不太好\",\"DACS 在絕大多數並非是最佳的結果上都不會離最佳太遠，除了 SW 頗偏\"]},\"33\":{\"h\":\"Some issues about evaluation\",\"t\":[\"他們認為在其他的 paper 有不少人最後給的結果之所以那麼好看是因為\",\"Cityscapes 並沒有 testset\",\"他們選擇用 validation set 判斷要不要 early stop，這個 validation set 也跟最後評估的 set 是一樣的\",\"針對 validation set 挑選 hyperparameters (?)\",\"所以他們認為這樣不太公平，畢竟在 Validation set 做得很棒不能直接表達在整體會表達很棒。 他們也試著用相同的手段訓練模型，然後拿到了\",\"GTA5 \",\"Baseline: 35.68% (+2.83%)\",\"DACS: 53.84% (+1.7%) (BEST)\",\"SYNTHIA \",\"DACS (13 classes): 55.98% (+1.17%) (1.02% to BEST)\",\"DACS (16 classes): 49.10% (+0.76%) (0.7% to BEST)\"]},\"34\":{\"h\":\"Contribution\",\"t\":[\"Apply SSL method on ClassMix to UDA\",\"Introduce a simple framework with high-performance\",\"Beat SOTA in GTA5 to Cityscape\"]},\"35\":{\"h\":\"值得一看的文章們\",\"t\":[\"【Day 24】半監督式學習（Semi-supervised Learning）（上）\",\"【Day 25】半監督式學習（Semi-supervised Learning）（下）\",\"Notes on “DACS: Domain Adaptation via Cross-domain Mixed Sampling”\",\"物件偵測的領域自適應 (Domain Adaptation)\",\"Adversarial Learning for Semi-Supervised Semantic Segmentation\",\"Domain Adaptation in Computer Vision: Everything You Need to Know\",\"Semi-supervised semantic segmentation needs strong, varied perturbations\",\"ClassMix: Segmentation-Based Data Augmentation for Semi-Supervised Learning\",\"Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training\",\"Learning to Adapt Structured Output Space for Semantic Segmentation\"]},\"36\":{\"c\":[\"Note\"]},\"37\":{\"c\":[\"Paper Read\",\"Domain Adaption\",\"Computer Vision\",\"WACV\"]},\"38\":{\"h\":\"2024 Google SWE Intern Interview 心得\",\"t\":[\"大概在今年的一月初投了履歷到 Google SWE，希望暑假可以去累積累積經驗，大概在幾天後就收到要填寫面試時間的通知信件，三周後收到了面試的通知。\",\"在面試前收到的信件都會很貼心地說明，也有提供一些線上的資源協助你去了解如何準備面試，甚至也可以直接跟對方來往信件去確認，我覺得這一點是還蠻不錯的。\",\"面試的流程大致上會分成兩場，兩場都是針對算法題目，不太會對簡歷或是個人背景去做提問，結束前也會有一小段可以任意問問題的時間。\",\"兩場面試基本上會被放在同一天當中，但是會在不同時段。以我自己來說，我分別是在早上跟下午各一場。一場時間大概是 45 分鐘。\",\"Info\",\"有趣的是，我們並不會在一般的 IDE 或是 Text Editor 上寫 code，而是 Google 會提供 Google Doc 在上面寫，而你的面試官也可以一起編輯，就像是實體面試的時候\\\"白板\\\"這個工具。\"]},\"39\":{\"h\":\"第一場面試\"},\"40\":{\"h\":\"Warnup\"},\"41\":{\"h\":\"題目敘述\",\"t\":[\"給定 N×M 的地圖，其中\",\"# 表示 wall\",\". 表示 road\",\"a 表示起點\",\"A 表示終點\",\"每次只能選上下左右一個方向去移動，問從 a 是否有辦法走到 A。\"]},\"42\":{\"h\":\"思路\",\"t\":[\"從起點做 BFS，看能不能走到終點\",\"bool FindExit(vector<vector<char>> maps){ // Find start point int rows = maps.size(); int cols = maps[0].size(); pair<int, int> start; for(int i=0 ; i<rows ; i++){ for(int j=0 ; j<cols ; j++){ if(maps[i][j] == 'a'){ start = make_pair(i, j); } } } // BFS from start point // initialize vis array bool vis[rows][cols]; for(int i=0 ; i<rows ; i++){ for(int j=0 ; j<cols ; j++){ vis[i][j] = false; } } // put start point queue<pair<int, int>> q; q.emplace(start); vis[start.first][start.second] = true; // For implementation simplicity int dx[] = {-1, 0, 1, 0}; int dy[] = {0, -1, 0, 1}; // BFS while(!q.empty()){ int x = q.front().first; int y = q.front().second; q.pop(); // check whether is answer or not if(maps[x][y] == 'A'){ return true; } for(int i=0 ; i<4 ; i++){ int nx = x + dx[i]; int ny = y + dy[i]; // check whether nx and ny is valid if(nx < 0 || nx >= rows || ny < 0 || ny >= cols) continue; // check whether visited if(vis[nx][ny]) continue; // check wall if(maps[nx][ny] == '#') continue; // otherwise, road or end point q.emplace(nx, ny); vis[nx][ny] = true; } } // Cannot reach the end point return false; } \"]},\"43\":{\"h\":\"Follow-up\"},\"44\":{\"h\":\"題目敘述\",\"t\":[\"現在把 a 當成是一台車，又再多一台車 b。\",\"a 一樣要到終點 A，b 則是要到終點 B。\",\"兩台車行走的時間可以隨意(也就是說，不需要一起移動一格)。\",\"問是否可以在不碰撞的情況下兩台車都到終點。\"]},\"45\":{\"h\":\"思路\",\"t\":[\"兩台車並不需要同時去運行，所以可以等某一台車通過之後再回到原本的位置。\",\"Tips\",\"舉例來說\",\"#B# a.A #b# \",\"這個 case 下可以先等 a 走到 A 之後 b 再移動，所以不會有碰撞出現\",\"不過底下這個 case 就無法避免碰撞而造成無解。\",\"#### aBAb #### \",\"這一題面試當下並沒有好的想法，最後也並沒有實際實作出來。\",\"不過大抵還是會使用 BFS 去解。\"]},\"46\":{\"h\":\"第一場面試小結\",\"t\":[\"當初填表單的時候好像不小心填到一場英文一場中文，所以那一場我是用英文面試的，還是有一定程度影響到輸出效果www\",\"第一場面試下來自己覺得有盡可能去溝通，也有先好好確認過題目的條件，不過 Follow-up 沒有找到一個好的想法覺得很可惜。即便是在面試結束之後想這個題目目前也還沒有什麼好的想法。\",\"我不太確定時間複雜度的部分是不是需要自己說明，面試官當時沒有提問到，我也就沒有額外補充說明這一塊，面試結束後覺得應該還是需要提的，因此下一場面試就有比較積極去說明自己的解法時間複雜度如何。\"]},\"47\":{\"h\":\"第二場面試\",\"t\":[\"經過了午餐的小休息之後，接下來就是第二場的面試。\"]},\"48\":{\"h\":\"Warn-up\"},\"49\":{\"h\":\"題目敘述\",\"t\":[\"給三個整數，找出中位數\"]},\"50\":{\"h\":\"思路\",\"t\":[\"只有三個數字，簡單條件判斷就可以出來了。\",\"int FindMedium(int a, int b, int c){ if(a <= b && b <= c) return b; if(a <= c && c <= b) return c; if(b <= a && a <= c) return a; if(b <= c && c <= a) return c; if(c <= b && b <= a) return b; if(c <= a && a <= b) return a; } \"]},\"51\":{\"h\":\"Question 1\",\"t\":[\"現在有 10 個人要安排會議日期，每個人都有一些 unavaliable 的日期，詢問有哪些大家都可行的日期。\",\"每個不能的日期會用下列的 struct 表示\",\"struct block{ int personId; // 表示是哪一個人的日期 int startDay; // 表示不能的開始時間 int endDay; // 表示不能的結束時間 }; \",\"整體安排的日期為 0~最大的 endDay + 1\"]},\"52\":{\"h\":\"思路 1\",\"t\":[\"對於每一天去看看有沒有任何不能的時段有重疊到他，沒有的話就放進答案，否則繼續看下一個。\",\"假設總共 M 個 block，安排的日期最多 N 天。每一天都需要去對 M 個 block 檢查，檢查一個 block 是 O(1)，因此總共時間複雜度是 O(NM)。\"]},\"53\":{\"h\":\"思路 2\",\"t\":[\"上面的解法也許有些暴力，況且 N 也有可能很大。\",\"考慮到排序往往會帶來不錯的性質，這裡先依照 startDay 由小到大排序，相同時則依照 endDay 由小到大。\",\"對於相鄰的兩個時段，如果說他們是有重疊的，那我們可以把它們合併在一起。否則就表示從現在的 endDay + 1 到下一個 startDay - 1 之間都會是可以的日期。\",\"如此一來對於每個 block 我們就可以只去考慮 startDay 以及 endDay。\",\"排序採用 merge sort 可以得到 O(MlogM) 的時間複雜度。\",\"看過一個 block 以及處理合併都只需要 O(1)，因此這一個步驟對每個 block 總共需要 O(M)。\",\"對於可以的時間需要逐一加入到答案當中，因此會需要額外 O(N) 的時間處理插入。\",\"總時間複雜度來到 O(MlogM+N+M)\",\"bool cmp(struct block p, struct block q){ if(p.startDay != q.startDay) return p.startDay < q.startDay; else return p.endDay < q.endDay; } vector<int> FindAvaliable(vector<block> v){ vector<int> ans; // sort the blocks sort(v.begin(), v.end(), cmp); // [0, v[0].startDay) should also be avaliable for(int i=0 ; i<v[0].startDay ; i++){ ans.emplace_back(i); } // Look over the whole blocks for(int i=0 ; i<v.size() ; i++){ // check whether there's next block if(i + 1 < v.size()){ // check whether we can merge two blocks if(v[i+1].endDay <= v[i].startDay){ // merge result to next block v[i+1].startDay = v[i].startDay; } else{ // otherwise, add (v[i].endDay, v[i+1].startDay) to answer for(int i=v[i].endDay+1 ; i<v[i+1].startDay ; i++){ ans.emplace_back(i); } } } else{ // No more blocks, we should add v[i].endDay + 1 to answer ans.emplace_back(v[i].endDay + 1); } } return ans; } \"]},\"54\":{\"h\":\"Question 1 - Follow-up\",\"t\":[\"現在多給你一個參數 k，請把所有 <=k 個人 unavaliable 的日期都列出來。\",\"保證不會有一個人自己填到重疊的時段\"]},\"55\":{\"h\":\"思路 1\",\"t\":[\"同樣可以採取暴力的做法，去看過每一個時間，check 是否 unavaliable 的人數是 <=k。\",\"每一個時間需要花 O(M) 去確認，總共有 N 個時間，總時間複雜度 O(NM)。\"]},\"56\":{\"h\":\"思路 2\",\"t\":[\"不妨把時段畫成圖，像是底下的樣子。\",\"--------- ----- ------- \",\"其實是哪一個人佔據了哪一個時段我們並不在乎，因為已經事先知道不會有人自己填到跟自己重疊的時段，所以我們只在乎美個時段有多少個重疊。\",\"當然，我們可以像 思路 1 一樣去算每一個時間點的人數，但是實際上人數只會在那些開始以及結束的點被更新。\",\"進到 startDay 人數就 +1\",\"進到 endDat 人數就 -1\",\"所以我們可以單純的去把所有的時間標記上他是 start 或是 end，然後拿去 sort。\",\"如此一來我們就能夠知道每一個時間段 unavaliable 的人數有多少了。\",\"製作出 Days 需要花 O(M) 的時間。排序需要 O(MlogM) 的時間。最後只需要掃過每一個 block 就可以知道有哪些時段需要插入，時間是 O(M)。記得也要考慮插入答案的 O(N)。\",\"總時間複雜度落在 O(M+MlogM+M+N)。\"]},\"57\":{\"h\":\"第二場面試小結\",\"t\":[\"這一場的發揮還算不錯，也頗主動去跟面試官互動，整體感覺下來很棒。\"]},\"58\":{\"h\":\"總結\",\"t\":[\"Google 的面試往往要求的是跟面試官之間的互動，以及有沒有辦法好好說明與想到解決方案。\",\"面試前沒有做什麼準備，實際上面試起來也覺得狀態還不錯，不過面試官主動的互動有比想像中少一些，像是時間複雜度的部分他們並不會直接詢問，說出一個解法之後似乎也不會說「有沒有更好的解法呢」之類的，而是說「如果你只想到這樣的話也可以開始寫 code，或是是著想想看有沒有其他想法」。\",\"一些小細節上跟預期有些落差，不過整體上我覺得是還蠻不錯的體驗。題目其實並不會過難，真的就是期待你可以現場去好好思考跟說明你的想法，把面試官當成是你的隊友去討論討論作法。\",\"最重要的也許是心態上的調整。面對面試如果過於緊張往往會無法順利面對突發狀況，需要好好整理心態，去面對未知的題目跟挑戰。\",\"期待後續的消息 ouob。\"]},\"59\":{\"c\":[\"Feedbacks\"]},\"60\":{\"c\":[\"Interview\",\"Google\"]},\"61\":{\"h\":\"Posts\"}},\"dirtCount\":0,\"index\":[[\"期待後續的消息\",{\"1\":{\"58\":1}}],[\"面對面試如果過於緊張往往會無法順利面對突發狀況\",{\"1\":{\"58\":1}}],[\"面試前沒有做什麼準備\",{\"1\":{\"58\":1}}],[\"面試結束後覺得應該還是需要提的\",{\"1\":{\"46\":1}}],[\"面試官當時沒有提問到\",{\"1\":{\"46\":1}}],[\"面試的流程大致上會分成兩場\",{\"1\":{\"38\":1}}],[\"真的就是期待你可以現場去好好思考跟說明你的想法\",{\"1\":{\"58\":1}}],[\"真的很糟\",{\"1\":{\"31\":1}}],[\"題目其實並不會過難\",{\"1\":{\"58\":1}}],[\"題目敘述\",{\"0\":{\"41\":1,\"44\":1,\"49\":1}}],[\"說出一個解法之後似乎也不會說\",{\"1\":{\"58\":1}}],[\"說明\",{\"1\":{\"6\":1}}],[\"整體感覺下來很棒\",{\"1\":{\"57\":1}}],[\"整體安排的日期為\",{\"1\":{\"51\":1}}],[\"記得也要考慮插入答案的\",{\"1\":{\"56\":1}}],[\"時間是\",{\"1\":{\"56\":1}}],[\"時常我們會訓練在合成資料上\",{\"1\":{\"16\":1}}],[\"排序需要\",{\"1\":{\"56\":1}}],[\"排序採用\",{\"1\":{\"53\":1}}],[\"需要好好整理心態\",{\"1\":{\"58\":1}}],[\"需要花\",{\"1\":{\"56\":1}}],[\"需要解出一些簡單的演算法題目\",{\"1\":{\"4\":1}}],[\"製作出\",{\"1\":{\"56\":1}}],[\"人數就\",{\"1\":{\"56\":2}}],[\"同樣可以採取暴力的做法\",{\"1\":{\"55\":1}}],[\"同樣以自駕車的例子來說\",{\"1\":{\"19\":1}}],[\"保證不會有一個人自己填到重疊的時段\",{\"1\":{\"54\":1}}],[\"請把所有\",{\"1\":{\"54\":1}}],[\"總時間複雜度落在\",{\"1\":{\"56\":1}}],[\"總時間複雜度\",{\"1\":{\"55\":1}}],[\"總時間複雜度來到\",{\"1\":{\"53\":1}}],[\"總共有\",{\"1\":{\"55\":1}}],[\"總共需要\",{\"1\":{\"53\":1}}],[\"總結\",{\"0\":{\"11\":1,\"58\":1}}],[\"否則就表示從現在的\",{\"1\":{\"53\":1}}],[\"否則繼續看下一個\",{\"1\":{\"52\":1}}],[\"由小到大\",{\"1\":{\"53\":1}}],[\"由小到大排序\",{\"1\":{\"53\":1}}],[\"況且\",{\"1\":{\"53\":1}}],[\"檢查一個\",{\"1\":{\"52\":1}}],[\"檢查\",{\"1\":{\"52\":1}}],[\"天\",{\"1\":{\"52\":1}}],[\"天空之類的就通常會像是在半空中\",{\"1\":{\"19\":1}}],[\"安排的日期最多\",{\"1\":{\"52\":1}}],[\"安全帽是甚麼顏色\",{\"1\":{\"5\":1}}],[\"假設總共\",{\"1\":{\"52\":1}}],[\"沒有的話就放進答案\",{\"1\":{\"52\":1}}],[\"沒有找到一個好的想法覺得很可惜\",{\"1\":{\"46\":1}}],[\"詢問有哪些大家都可行的日期\",{\"1\":{\"51\":1}}],[\"找出中位數\",{\"1\":{\"49\":1}}],[\"給三個整數\",{\"1\":{\"49\":1}}],[\"給定\",{\"1\":{\"41\":1}}],[\"接下來就是第二場的面試\",{\"1\":{\"47\":1}}],[\"再移動\",{\"1\":{\"45\":1}}],[\"走到\",{\"1\":{\"45\":1}}],[\"則是要到終點\",{\"1\":{\"44\":1}}],[\"則是現實世界當中的影像\",{\"1\":{\"27\":1}}],[\"又再多一台車\",{\"1\":{\"44\":1}}],[\"現在多給你一個參數\",{\"1\":{\"54\":1}}],[\"現在有\",{\"1\":{\"51\":1}}],[\"現在把\",{\"1\":{\"44\":1}}],[\"現實很骨感\",{\"1\":{\"6\":1}}],[\"||\",{\"1\":{\"42\":3}}],[\"<=k\",{\"1\":{\"54\":1,\"55\":1}}],[\"<=\",{\"1\":{\"50\":12,\"53\":1}}],[\"<\",{\"1\":{\"42\":2,\"53\":3}}],[\"q\",{\"1\":{\"42\":7,\"53\":4}}],[\"question\",{\"0\":{\"51\":1,\"54\":1}}],[\"queue<pair<int\",{\"1\":{\"42\":1}}],[\"qualification\",{\"1\":{\"2\":1}}],[\"==\",{\"1\":{\"42\":3}}],[\"=\",{\"1\":{\"42\":12,\"53\":2}}],[\"=e\",{\"1\":{\"24\":1}}],[\"思路\",{\"0\":{\"42\":1,\"45\":1,\"50\":1,\"52\":1,\"53\":1,\"55\":1,\"56\":1},\"1\":{\"56\":1}}],[\"問是否可以在不碰撞的情況下兩台車都到終點\",{\"1\":{\"44\":1}}],[\"問從\",{\"1\":{\"41\":1}}],[\"問題在於不同的\",{\"1\":{\"17\":1}}],[\"問題描述\",{\"0\":{\"17\":1}}],[\"每一個時間需要花\",{\"1\":{\"55\":1}}],[\"每一天都需要去對\",{\"1\":{\"52\":1}}],[\"每個不能的日期會用下列的\",{\"1\":{\"51\":1}}],[\"每個人都有一些\",{\"1\":{\"51\":1}}],[\"每個人題目會不太相同\",{\"1\":{\"4\":1}}],[\"每次只能選上下左右一個方向去移動\",{\"1\":{\"41\":1}}],[\"表示不能的結束時間\",{\"1\":{\"51\":1}}],[\"表示不能的開始時間\",{\"1\":{\"51\":1}}],[\"表示是哪一個人的日期\",{\"1\":{\"51\":1}}],[\"表示終點\",{\"1\":{\"41\":1}}],[\"表示起點\",{\"1\":{\"41\":1}}],[\"表示\",{\"1\":{\"41\":2,\"51\":1}}],[\"白板\",{\"1\":{\"38\":1}}],[\"分鐘\",{\"1\":{\"38\":1}}],[\"分組第三名\",{\"1\":{\"2\":1}}],[\"以我自己來說\",{\"1\":{\"38\":1}}],[\"以及有沒有辦法好好說明與想到解決方案\",{\"1\":{\"58\":1}}],[\"以及處理合併都只需要\",{\"1\":{\"53\":1}}],[\"以及加上\",{\"1\":{\"7\":1}}],[\"以及\",{\"1\":{\"0\":1,\"6\":1,\"16\":1,\"19\":2,\"23\":1,\"24\":1,\"27\":1,\"53\":1}}],[\"結束前也會有一小段可以任意問問題的時間\",{\"1\":{\"38\":1}}],[\"結果相當糟糕\",{\"1\":{\"17\":1}}],[\"結果\",{\"0\":{\"9\":1}}],[\"兩台車並不需要同時去運行\",{\"1\":{\"45\":1}}],[\"兩台車行走的時間可以隨意\",{\"1\":{\"44\":1}}],[\"兩場面試基本上會被放在同一天當中\",{\"1\":{\"38\":1}}],[\"兩場都是針對算法題目\",{\"1\":{\"38\":1}}],[\"兩個\",{\"1\":{\"19\":1}}],[\"三周後收到了面試的通知\",{\"1\":{\"38\":1}}],[\"k\",{\"1\":{\"54\":1}}],[\"know\",{\"1\":{\"35\":1}}],[\"kick\",{\"1\":{\"2\":2}}],[\"物件偵測的領域自適應\",{\"1\":{\"35\":1}}],[\"下可以先等\",{\"1\":{\"45\":1}}],[\"下\",{\"1\":{\"35\":1}}],[\"下拍攝\",{\"1\":{\"30\":1}}],[\"下拍攝的\",{\"1\":{\"29\":1}}],[\"值得一看的文章們\",{\"0\":{\"35\":1}}],[\"0~最大的\",{\"1\":{\"51\":1}}],[\"0\",{\"1\":{\"33\":1,\"42\":7,\"53\":3}}],[\"02\",{\"1\":{\"33\":1}}],[\"+\",{\"1\":{\"42\":2,\"51\":1,\"53\":4}}],[\"+0\",{\"1\":{\"33\":1}}],[\"+1\",{\"1\":{\"33\":2,\"56\":1}}],[\"+2\",{\"1\":{\"33\":1}}],[\"+λh\",{\"1\":{\"24\":1}}],[\"挑選\",{\"1\":{\"33\":1}}],[\"針對\",{\"1\":{\"33\":1}}],[\"判斷要不要\",{\"1\":{\"33\":1}}],[\"並沒有\",{\"1\":{\"33\":1}}],[\"並不一定要是\",{\"1\":{\"31\":1}}],[\"並不是所有的\",{\"1\":{\"20\":1}}],[\"他們也試著用相同的手段訓練模型\",{\"1\":{\"33\":1}}],[\"他們選擇用\",{\"1\":{\"33\":1}}],[\"他們選擇其中\",{\"1\":{\"31\":1}}],[\"他們認為在其他的\",{\"1\":{\"33\":1}}],[\"頗偏\",{\"1\":{\"32\":1}}],[\"甚至也可以直接跟對方來往信件去確認\",{\"1\":{\"38\":1}}],[\"甚至對\",{\"1\":{\"32\":1}}],[\"甚至連\",{\"1\":{\"10\":1}}],[\"使用\",{\"1\":{\"32\":1}}],[\"使得同類型的資料會相近\",{\"1\":{\"16\":1}}],[\"考慮到排序往往會帶來不錯的性質\",{\"1\":{\"53\":1}}],[\"考慮到\",{\"1\":{\"32\":1}}],[\"除了\",{\"1\":{\"31\":1,\"32\":1}}],[\"單純用\",{\"1\":{\"31\":1,\"32\":1}}],[\"單純的\",{\"1\":{\"23\":1}}],[\"個時間\",{\"1\":{\"55\":1}}],[\"個人\",{\"1\":{\"54\":1}}],[\"個人要安排會議日期\",{\"1\":{\"51\":1}}],[\"個的平均\",{\"1\":{\"32\":1}}],[\"個平均跟\",{\"1\":{\"32\":1}}],[\"個\",{\"1\":{\"30\":1,\"32\":2,\"52\":2}}],[\"建構的\",{\"1\":{\"30\":1}}],[\"可對應到\",{\"1\":{\"29\":1}}],[\"可以得到\",{\"1\":{\"53\":1}}],[\"可以發現\",{\"1\":{\"31\":1,\"32\":1}}],[\"可以發現單純用\",{\"1\":{\"17\":1}}],[\"可以分成\",{\"1\":{\"19\":1}}],[\"可以嘗試\",{\"1\":{\"6\":1}}],[\"可以自己使用的免費咖啡機\",{\"1\":{\"6\":1}}],[\"照片是在\",{\"1\":{\"29\":1,\"30\":1}}],[\"照片是在城市當中開車拍下的各種照片\",{\"1\":{\"28\":1}}],[\"照片中有多少人\",{\"1\":{\"5\":1}}],[\">=\",{\"1\":{\"42\":2}}],[\">\",{\"0\":{\"31\":1,\"32\":1},\"1\":{\"27\":2}}],[\"作為\",{\"1\":{\"26\":1}}],[\"搭配\",{\"1\":{\"26\":1}}],[\"選擇採用\",{\"1\":{\"26\":1}}],[\"θ\",{\"1\":{\"24\":1}}],[\"部分的影響程度\",{\"1\":{\"24\":1}}],[\"調整\",{\"1\":{\"24\":1}}],[\"λ\",{\"1\":{\"24\":1}}],[\"得到\",{\"1\":{\"24\":1}}],[\"經過了午餐的小休息之後\",{\"1\":{\"47\":1}}],[\"經過\",{\"1\":{\"24\":1}}],[\"經過相同的\",{\"1\":{\"19\":1}}],[\"取得\",{\"1\":{\"24\":1}}],[\"取出圖片\",{\"1\":{\"24\":1}}],[\"取出圖片與\",{\"1\":{\"24\":1}}],[\"從起點做\",{\"1\":{\"42\":1}}],[\"從\",{\"1\":{\"24\":2}}],[\"詳細的步驟具體來說\",{\"1\":{\"24\":1}}],[\"會提供\",{\"1\":{\"38\":1}}],[\"會造成的問題是吻合的\",{\"1\":{\"23\":1}}],[\"會不同\",{\"1\":{\"17\":1}}],[\"覆蓋\",{\"1\":{\"23\":1}}],[\"許多的\",{\"1\":{\"23\":1}}],[\"之間都會是可以的日期\",{\"1\":{\"53\":1}}],[\"之後\",{\"1\":{\"45\":1}}],[\"之類的\",{\"1\":{\"23\":1,\"58\":1}}],[\"之前的想法是先去做一些\",{\"1\":{\"6\":1}}],[\"被預測成\",{\"1\":{\"23\":2}}],[\"拿去訓練\",{\"1\":{\"23\":1,\"24\":1}}],[\"拿出兩張\",{\"1\":{\"21\":1}}],[\"將\",{\"1\":{\"23\":1,\"24\":1}}],[\"將產出的\",{\"1\":{\"19\":1}}],[\"進到\",{\"1\":{\"56\":2}}],[\"進而解決這個問題\",{\"1\":{\"21\":1}}],[\"進入決賽\",{\"1\":{\"2\":1}}],[\"邊界上的判斷會因為圖片跟相鄰環境的相似導致模糊不清\",{\"1\":{\"21\":1}}],[\"x\",{\"1\":{\"42\":3}}],[\"xm​\",{\"1\":{\"24\":4}}],[\"xt​\",{\"1\":{\"24\":3}}],[\"xs​\",{\"1\":{\"24\":5}}],[\"xa​\",{\"1\":{\"21\":2}}],[\"x2\",{\"1\":{\"5\":1}}],[\"合成出\",{\"1\":{\"21\":2}}],[\"跟\",{\"1\":{\"21\":2,\"24\":1,\"26\":1}}],[\"跟過去自己想像當中在無塵室裏面處理晶圓的那種印象是完全不同\",{\"1\":{\"11\":1}}],[\"先轉成\",{\"1\":{\"21\":1}}],[\"先在\",{\"1\":{\"20\":1}}],[\"把面試官當成是你的隊友去討論討論作法\",{\"1\":{\"58\":1}}],[\"把\",{\"1\":{\"21\":3,\"23\":1,\"24\":1}}],[\"把兩個圖片\",{\"1\":{\"21\":1}}],[\"把輸出結果套入\",{\"1\":{\"10\":1}}],[\"具體來說\",{\"1\":{\"21\":1}}],[\"方法\",{\"1\":{\"21\":1}}],[\"方法也是屬於\",{\"1\":{\"21\":1}}],[\"像是時間複雜度的部分他們並不會直接詢問\",{\"1\":{\"58\":1}}],[\"像是底下的樣子\",{\"1\":{\"56\":1}}],[\"像是\",{\"1\":{\"21\":1,\"23\":1,\"31\":1}}],[\"像是直接有一台車會去蒐集真實街景資料\",{\"1\":{\"16\":1}}],[\"混合成新的圖片\",{\"1\":{\"21\":1}}],[\"產生一個新的\",{\"1\":{\"21\":1}}],[\"提出如\",{\"1\":{\"20\":1}}],[\"雖然已經有\",{\"1\":{\"20\":1}}],[\"雖然說在比賽之前我們的想法是\",{\"1\":{\"6\":1}}],[\"雖然說是黑客松\",{\"1\":{\"6\":1}}],[\"45\",{\"1\":{\"38\":1}}],[\"49\",{\"1\":{\"33\":1}}],[\"4\",{\"1\":{\"20\":1}}],[\"44\",{\"1\":{\"9\":1}}],[\"zou\",{\"1\":{\"20\":1}}],[\"zhang\",{\"1\":{\"17\":1}}],[\"導致卡車時常被預測成汽車\",{\"1\":{\"20\":1}}],[\"導致預測失準\",{\"1\":{\"17\":1}}],[\"或是是著想想看有沒有其他想法\",{\"1\":{\"58\":1}}],[\"或是\",{\"1\":{\"38\":1,\"56\":1}}],[\"或是汽車比卡車更常見\",{\"1\":{\"20\":1}}],[\"或是看起來安全帽是後製貼上去的\",{\"1\":{\"7\":1}}],[\"例如說在自駕車的道路辨識當中鄰近人行道這種時常出現的\",{\"1\":{\"20\":1}}],[\"來說由於缺乏對於\",{\"1\":{\"20\":1}}],[\"來說是相當大的問題\",{\"1\":{\"20\":1}}],[\"對應的\",{\"1\":{\"21\":2}}],[\"對陌生人的認識\",{\"1\":{\"20\":1}}],[\"對於可以的時間需要逐一加入到答案當中\",{\"1\":{\"53\":1}}],[\"對於相鄰的兩個時段\",{\"1\":{\"53\":1}}],[\"對於每一天去看看有沒有任何不能的時段有重疊到他\",{\"1\":{\"52\":1}}],[\"對於\",{\"1\":{\"20\":1}}],[\"對抗式學習\",{\"1\":{\"19\":1}}],[\"缺乏\",{\"1\":{\"20\":1}}],[\"換句話說\",{\"1\":{\"20\":1}}],[\"up\",{\"0\":{\"43\":1,\"48\":1,\"54\":1},\"1\":{\"46\":1}}],[\"uda\",{\"0\":{\"23\":1},\"1\":{\"20\":4,\"23\":2,\"34\":1}}],[\"unavaliable\",{\"1\":{\"51\":1,\"54\":1,\"55\":1,\"56\":1}}],[\"unlabelled\",{\"1\":{\"23\":1}}],[\"unlabeled\",{\"1\":{\"20\":3,\"21\":1}}],[\"unlebelled\",{\"1\":{\"23\":1}}],[\"unsupervised\",{\"1\":{\"20\":1}}],[\"unity\",{\"1\":{\"30\":1}}],[\"university\",{\"1\":{\"15\":1}}],[\"unix\",{\"1\":{\"1\":1}}],[\"尤其在\",{\"1\":{\"20\":1}}],[\"尤其是從\",{\"1\":{\"17\":1}}],[\"畢竟在\",{\"1\":{\"33\":1}}],[\"畢竟\",{\"1\":{\"20\":1}}],[\"了\",{\"1\":{\"20\":1}}],[\"做得很棒不能直接表達在整體會表達很棒\",{\"1\":{\"33\":1}}],[\"做出一個\",{\"1\":{\"21\":1}}],[\"做\",{\"1\":{\"20\":1}}],[\"做對抗式學習\",{\"1\":{\"19\":1}}],[\"舉例來說\",{\"1\":{\"20\":1,\"45\":1}}],[\"舉一個在\",{\"1\":{\"16\":1}}],[\"那我們可以把它們合併在一起\",{\"1\":{\"53\":1}}],[\"那我們就可以用\",{\"1\":{\"20\":1}}],[\"那我們不要用\",{\"1\":{\"6\":1}}],[\"而你的面試官也可以一起編輯\",{\"1\":{\"38\":1}}],[\"而是說\",{\"1\":{\"58\":1}}],[\"而是\",{\"1\":{\"38\":1}}],[\"而是將\",{\"1\":{\"24\":1}}],[\"而\",{\"1\":{\"20\":1,\"26\":1,\"27\":1}}],[\"而半監督式學習困難的點在於雖然對於\",{\"1\":{\"20\":1}}],[\"而被提出的\",{\"1\":{\"20\":1}}],[\"半監督式學習\",{\"1\":{\"20\":1,\"35\":2}}],[\"最重要的也許是心態上的調整\",{\"1\":{\"58\":1}}],[\"最好的\",{\"1\":{\"31\":1}}],[\"最\",{\"1\":{\"23\":1}}],[\"最初被用於把\",{\"1\":{\"21\":1}}],[\"最初是為了解決\",{\"1\":{\"20\":1}}],[\"最後只需要掃過每一個\",{\"1\":{\"56\":1}}],[\"最後只有\",{\"1\":{\"6\":1}}],[\"最後也並沒有實際實作出來\",{\"1\":{\"45\":1}}],[\"最後在\",{\"1\":{\"9\":1}}],[\"號誌\",{\"1\":{\"19\":1}}],[\"行人都還是會跟地板黏在一起\",{\"1\":{\"19\":1}}],[\"汽車\",{\"1\":{\"19\":1}}],[\"和\",{\"1\":{\"19\":1,\"20\":1}}],[\"即便是在面試結束之後想這個題目目前也還沒有什麼好的想法\",{\"1\":{\"46\":1}}],[\"即便\",{\"1\":{\"19\":1}}],[\"通常並不會差太多\",{\"1\":{\"19\":1}}],[\"等不同的做法\",{\"1\":{\"19\":1}}],[\"依照\",{\"1\":{\"19\":1}}],[\"中各取圖片\",{\"1\":{\"19\":1}}],[\"中間還有提供午餐\",{\"1\":{\"6\":1}}],[\"還是有一定程度影響到輸出效果www\",{\"1\":{\"46\":1}}],[\"還是存在差異的\",{\"1\":{\"20\":1}}],[\"還是\",{\"1\":{\"19\":1}}],[\"還要強許多\",{\"1\":{\"6\":1}}],[\"透過一些方式混在一起\",{\"1\":{\"21\":1}}],[\"透過這個模型我們就有辦法給\",{\"1\":{\"20\":1}}],[\"透過\",{\"1\":{\"19\":1,\"24\":1}}],[\"直接把訓練在虛擬環境的模型應用在真實環境\",{\"1\":{\"17\":1}}],[\"擅自用自己的思維解讀\",{\"1\":{\"17\":1}}],[\"因為已經事先知道不會有人自己填到跟自己重疊的時段\",{\"1\":{\"56\":1}}],[\"因為缺乏對他人的理解\",{\"1\":{\"17\":1}}],[\"因此會需要額外\",{\"1\":{\"53\":1}}],[\"因此這一個步驟對每個\",{\"1\":{\"53\":1}}],[\"因此這時候\",{\"1\":{\"21\":1}}],[\"因此總共時間複雜度是\",{\"1\":{\"52\":1}}],[\"因此下一場面試就有比較積極去說明自己的解法時間複雜度如何\",{\"1\":{\"46\":1}}],[\"因此\",{\"1\":{\"16\":1}}],[\"因此不少組別在實際進到\",{\"1\":{\"6\":1}}],[\"只對簡單的\",{\"1\":{\"31\":1}}],[\"只有三個數字\",{\"1\":{\"50\":1}}],[\"只有\",{\"1\":{\"20\":1}}],[\"只訓練在\",{\"1\":{\"17\":1}}],[\"只能說在設備上直接贏了\",{\"1\":{\"6\":1}}],[\"各自的\",{\"1\":{\"17\":1}}],[\"轉變到\",{\"1\":{\"17\":1}}],[\"不妨把時段畫成圖\",{\"1\":{\"56\":1}}],[\"不需要一起移動一格\",{\"1\":{\"44\":1}}],[\"不太會對簡歷或是個人背景去做提問\",{\"1\":{\"38\":1}}],[\"不太好\",{\"1\":{\"17\":1}}],[\"不同\",{\"1\":{\"19\":1}}],[\"不過整體上我覺得是還蠻不錯的體驗\",{\"1\":{\"58\":1}}],[\"不過面試官主動的互動有比想像中少一些\",{\"1\":{\"58\":1}}],[\"不過\",{\"1\":{\"46\":1}}],[\"不過大抵還是會使用\",{\"1\":{\"45\":1}}],[\"不過底下這個\",{\"1\":{\"45\":1}}],[\"不過這裡最主要都是使用\",{\"1\":{\"26\":1}}],[\"不過這種情況下一個直覺的問題是\",{\"1\":{\"16\":1}}],[\"不過像是馬路\",{\"1\":{\"19\":1}}],[\"不過如果遇到新的\",{\"1\":{\"17\":1}}],[\"不過實際上在實作的時候光是硬體的資源可能就是一大障礙\",{\"1\":{\"11\":1}}],[\"不過理想很美好\",{\"1\":{\"6\":1}}],[\"不過寄信去詢問之後得到希望還是使用到\",{\"1\":{\"6\":1}}],[\"不過場地因為是辦公室\",{\"1\":{\"6\":1}}],[\"往往在邊界上會有許多誤判的\",{\"1\":{\"23\":1}}],[\"往往先從貼標籤開始\",{\"1\":{\"20\":1}}],[\"往往就會\",{\"1\":{\"17\":1}}],[\"往往會有許多我們沒有的\",{\"1\":{\"16\":1}}],[\"影像分割\",{\"1\":{\"17\":1}}],[\"近年來透過\",{\"1\":{\"17\":1}}],[\"然後拿去\",{\"1\":{\"56\":1}}],[\"然後拿到了\",{\"1\":{\"33\":1}}],[\"然後會有一個\",{\"1\":{\"19\":1}}],[\"然後應用在真實的環境當中\",{\"1\":{\"16\":1}}],[\"然後再應用在真實的世界當中\",{\"1\":{\"16\":1}}],[\"讓我們得以用較低的成本在虛擬環境中訓練模型\",{\"1\":{\"16\":1}}],[\"降低\",{\"1\":{\"16\":1,\"24\":1}}],[\"想解決的就是盡可能地將\",{\"1\":{\"16\":1}}],[\"到下一個\",{\"1\":{\"53\":1}}],[\"到\",{\"1\":{\"16\":1}}],[\"就無法避免碰撞而造成無解\",{\"1\":{\"45\":1}}],[\"就像是實體面試的時候\",{\"1\":{\"38\":1}}],[\"就能夠比較好發揮作用\",{\"1\":{\"21\":1}}],[\"就可以知道有哪些時段需要插入\",{\"1\":{\"56\":1}}],[\"就可以再拿去\",{\"1\":{\"20\":1}}],[\"就可以得到相當好的影像分割結果\",{\"1\":{\"17\":1}}],[\"就相當地雷同\",{\"1\":{\"19\":1}}],[\"就會導致互相的不理解\",{\"1\":{\"17\":1}}],[\"就會導致單純在\",{\"1\":{\"16\":1}}],[\"就是希望\",{\"1\":{\"24\":1}}],[\"就是\",{\"1\":{\"19\":1,\"23\":1}}],[\"就是用來描述一群資料他們的分布狀況\",{\"1\":{\"16\":1}}],[\"就是拿來做簡報\",{\"1\":{\"6\":1}}],[\"過高\",{\"1\":{\"16\":1}}],[\"過去基本上就是看過\",{\"1\":{\"11\":1}}],[\"過去曾擔任臺南一中資訊社社長\",{\"1\":{\"0\":1}}],[\"相同時則依照\",{\"1\":{\"53\":1}}],[\"相鄰而導致的誤判被稱為\",{\"1\":{\"23\":1}}],[\"相差過大\",{\"1\":{\"16\":1}}],[\"相當佩服\",{\"1\":{\"10\":1}}],[\"環境與虛擬世界有差距\",{\"1\":{\"16\":1}}],[\"虛擬世界\",{\"1\":{\"16\":1}}],[\"在上面寫\",{\"1\":{\"38\":1}}],[\"在面試前收到的信件都會很貼心地說明\",{\"1\":{\"38\":1}}],[\"在絕大多數並非是最佳的結果上都不會離最佳太遠\",{\"1\":{\"31\":1,\"32\":1}}],[\"在邊界上往往會出現誤差的問題解決\",{\"1\":{\"21\":1}}],[\"在\",{\"1\":{\"16\":1,\"19\":1,\"20\":1,\"21\":2,\"23\":1,\"24\":1,\"26\":2,\"27\":1}}],[\"在提供的\",{\"1\":{\"7\":1}}],[\"很多時候我們並不會直接去蒐集真實的資料\",{\"1\":{\"16\":1}}],[\"反之則相遠\",{\"1\":{\"16\":1}}],[\"投射到同一個平面上\",{\"1\":{\"16\":1}}],[\"所謂的半監督式學習也就是說\",{\"1\":{\"20\":1}}],[\"所謂的\",{\"1\":{\"16\":1,\"20\":1}}],[\"所以我們可以單純的去把所有的時間標記上他是\",{\"1\":{\"56\":1}}],[\"所以我們只在乎美個時段有多少個重疊\",{\"1\":{\"56\":1}}],[\"所以我們後續就主要專攻\",{\"1\":{\"6\":1}}],[\"所以我們後續的方向都著重在\",{\"1\":{\"6\":1}}],[\"所以那一場我是用英文面試的\",{\"1\":{\"46\":1}}],[\"所以不會有碰撞出現\",{\"1\":{\"45\":1}}],[\"所以可以等某一台車通過之後再回到原本的位置\",{\"1\":{\"45\":1}}],[\"所以他們認為這樣不太公平\",{\"1\":{\"33\":1}}],[\"所以在數據上\",{\"1\":{\"32\":1}}],[\"所以在前面加上了一些\",{\"1\":{\"7\":1}}],[\"所以就讓他專門來回答這個問題\",{\"1\":{\"8\":1}}],[\"所以晚上\",{\"1\":{\"6\":1}}],[\"所以會有額外的提問\",{\"1\":{\"5\":1}}],[\"共同發表\",{\"1\":{\"15\":1}}],[\"與\",{\"1\":{\"15\":1}}],[\"查爾摩斯理工大學\",{\"1\":{\"15\":1}}],[\"we\",{\"1\":{\"53\":2}}],[\"whole\",{\"1\":{\"53\":1}}],[\"whether\",{\"1\":{\"42\":3,\"53\":2}}],[\"while\",{\"1\":{\"42\":1}}],[\"what\",{\"0\":{\"16\":1}}],[\"with\",{\"1\":{\"34\":1}}],[\"wilhelm\",{\"1\":{\"23\":2,\"24\":2,\"31\":2,\"32\":1}}],[\"winter\",{\"1\":{\"15\":1}}],[\"works\",{\"0\":{\"18\":1}}],[\"work\",{\"1\":{\"17\":1}}],[\"warn\",{\"0\":{\"48\":1}}],[\"warnup\",{\"0\":{\"40\":1}}],[\"warning\",{\"1\":{\"5\":3}}],[\"wall\",{\"1\":{\"30\":1,\"41\":1,\"42\":1}}],[\"wacv\",{\"1\":{\"15\":1},\"2\":{\"37\":1}}],[\"感到很開心\",{\"1\":{\"11\":1}}],[\"讀的時候都覺得嗯嗯嗯很有道理\",{\"1\":{\"11\":1}}],[\"當然\",{\"1\":{\"56\":1}}],[\"當初填表單的時候好像不小心填到一場英文一場中文\",{\"1\":{\"46\":1}}],[\"當成是一台車\",{\"1\":{\"44\":1}}],[\"當兩個\",{\"1\":{\"16\":1}}],[\"當時有遇到問題去找他們的時候都可以得到即時的\",{\"1\":{\"11\":1}}],[\"當中使用的是\",{\"1\":{\"21\":1}}],[\"當中通常\",{\"1\":{\"20\":1}}],[\"當中\",{\"1\":{\"7\":1,\"23\":1}}],[\"我也就沒有額外補充說明這一塊\",{\"1\":{\"46\":1}}],[\"我也能感受到每個員工對我們都很友善\",{\"1\":{\"11\":1}}],[\"我不太確定時間複雜度的部分是不是需要自己說明\",{\"1\":{\"46\":1}}],[\"我分別是在早上跟下午各一場\",{\"1\":{\"38\":1}}],[\"我覺得這一點是還蠻不錯的\",{\"1\":{\"38\":1}}],[\"我覺得這次到\",{\"1\":{\"11\":1}}],[\"我們可以像\",{\"1\":{\"56\":1}}],[\"我們可以想成現在\",{\"1\":{\"19\":1}}],[\"我們就可以只去考慮\",{\"1\":{\"53\":1}}],[\"我們並不會在一般的\",{\"1\":{\"38\":1}}],[\"我們對於\",{\"1\":{\"20\":1}}],[\"我們相信那些回答分數比較高的模型可以做得比較好\",{\"1\":{\"8\":1}}],[\"我們最後決定要把多個模型的輸出拿去做類似\",{\"1\":{\"8\":1}}],[\"我們也發現到說在回答顏色的那一題\",{\"1\":{\"7\":1}}],[\"我們想說這裡根本沒人戴安全帽\",{\"1\":{\"7\":1}}],[\"我們發現其中兩份都是教室的監視器錄影畫面\",{\"1\":{\"7\":1}}],[\"我們在\",{\"1\":{\"7\":1}}],[\"我們這一組在\",{\"1\":{\"6\":1}}],[\"我們這一組拿到的是\",{\"1\":{\"5\":1}}],[\"y\",{\"1\":{\"42\":3}}],[\"you\",{\"1\":{\"35\":1}}],[\"yolo\",{\"1\":{\"10\":1}}],[\"ym​\",{\"1\":{\"24\":4}}],[\"yt​^​\",{\"1\":{\"24\":2}}],[\"ytp\",{\"1\":{\"2\":1}}],[\"ys​\",{\"1\":{\"24\":5}}],[\"ya​\",{\"1\":{\"21\":1}}],[\"yang\",{\"1\":{\"20\":1}}],[\"yi\",{\"1\":{\"19\":2,\"26\":1}}],[\"yiheng\",{\"1\":{\"17\":1}}],[\"印象中有人用了\",{\"1\":{\"10\":1}}],[\"認識到其他組都用了怎樣的方法去解決\",{\"1\":{\"10\":1}}],[\"報告期間也都會跟我們分享他們覺得在每個地方有哪些比較好的做法也許可以嘗試看看\",{\"1\":{\"10\":1}}],[\"報告\",{\"0\":{\"10\":1}}],[\"加權分數\",{\"1\":{\"9\":1}}],[\"76\",{\"1\":{\"33\":1}}],[\"70\",{\"1\":{\"9\":1}}],[\"7\",{\"1\":{\"9\":2,\"33\":2}}],[\"上面的解法也許有些暴力\",{\"1\":{\"53\":1}}],[\"上寫\",{\"1\":{\"38\":1}}],[\"上會發生\",{\"1\":{\"23\":1}}],[\"上訓練一個模型\",{\"1\":{\"20\":1}}],[\"上訓練的模型難以直接\",{\"1\":{\"16\":1}}],[\"上\",{\"1\":{\"16\":1,\"21\":2,\"35\":1}}],[\"上也許我們能夠對各種物件去做標記\",{\"1\":{\"16\":1}}],[\"上的認知\",{\"1\":{\"20\":1}}],[\"上的\",{\"1\":{\"19\":1}}],[\"上的時候\",{\"1\":{\"17\":1}}],[\"上的例子\",{\"1\":{\"16\":1}}],[\"上的分數大概是\",{\"1\":{\"9\":1}}],[\"上看起來很棒\",{\"1\":{\"8\":1}}],[\"如此一來我們就能夠知道每一個時間段\",{\"1\":{\"56\":1}}],[\"如此一來對於每個\",{\"1\":{\"53\":1}}],[\"如此一來\",{\"1\":{\"24\":1}}],[\"如此一來就可以得到完整的輸出結果\",{\"1\":{\"8\":1}}],[\"如果你只想到這樣的話也可以開始寫\",{\"1\":{\"58\":1}}],[\"如果說他們是有重疊的\",{\"1\":{\"53\":1}}],[\"如果出現道路或甚至機車\",{\"1\":{\"20\":1}}],[\"如果我們想要訓練一個模型去做自駕車的街景物件偵測\",{\"1\":{\"16\":1}}],[\"如果只會問那些固定的問題的話\",{\"1\":{\"6\":1}}],[\"這一場的發揮還算不錯\",{\"1\":{\"57\":1}}],[\"這一題面試當下並沒有好的想法\",{\"1\":{\"45\":1}}],[\"這裡先依照\",{\"1\":{\"53\":1}}],[\"這個工具\",{\"1\":{\"38\":1}}],[\"這個\",{\"1\":{\"33\":1,\"45\":1}}],[\"這些普遍做得不錯的\",{\"1\":{\"31\":1}}],[\"這跟前面提到只使用\",{\"1\":{\"23\":1}}],[\"這種相似的\",{\"1\":{\"23\":1}}],[\"這種\",{\"1\":{\"21\":2}}],[\"這種狀況下訓練模型就被稱為半監督式學習\",{\"1\":{\"20\":1}}],[\"這種差距被描述為\",{\"1\":{\"16\":1}}],[\"這類的\",{\"1\":{\"19\":1}}],[\"這樣的問題只在\",{\"1\":{\"23\":1}}],[\"這樣的做法有趣的是能夠將\",{\"1\":{\"21\":1}}],[\"這樣的做法之所以可行\",{\"1\":{\"19\":1}}],[\"這樣所需要的成本會過大\",{\"1\":{\"16\":1}}],[\"這就像是同理心\",{\"1\":{\"17\":1}}],[\"這次大概是第一次實際碰\",{\"1\":{\"11\":1}}],[\"這七個問題\",{\"1\":{\"8\":1}}],[\"這場比賽是一組四人的比賽\",{\"1\":{\"4\":1}}],[\"簡單條件判斷就可以出來了\",{\"1\":{\"50\":1}}],[\"簡單來說\",{\"1\":{\"8\":1}}],[\"簡單的\",{\"1\":{\"4\":1}}],[\"答案產出\",{\"0\":{\"8\":1}}],[\"交叉做了一些\",{\"1\":{\"7\":1}}],[\"是否\",{\"1\":{\"55\":1}}],[\"是否有辦法走到\",{\"1\":{\"41\":1}}],[\"是否有比較好\",{\"1\":{\"7\":1}}],[\"是只有使用\",{\"1\":{\"31\":1}}],[\"是\",{\"1\":{\"26\":1,\"52\":1}}],[\"是一樣的\",{\"1\":{\"33\":1}}],[\"是一種\",{\"1\":{\"21\":1}}],[\"是一個讓人很喜歡的環境\",{\"1\":{\"11\":1}}],[\"是源自於即便\",{\"1\":{\"19\":1}}],[\"是也可以都\",{\"1\":{\"6\":1}}],[\"實驗設定\",{\"0\":{\"26\":1}}],[\"實驗上為了檢測拿掉兩個\",{\"1\":{\"7\":1}}],[\"實際上面試起來也覺得狀態還不錯\",{\"1\":{\"58\":1}}],[\"實際上我們挑了最小的\",{\"1\":{\"6\":1}}],[\"實際上在辦公室的時間沒有想像中的還要多\",{\"1\":{\"6\":1}}],[\"吐出更多結果\",{\"1\":{\"7\":1}}],[\"試圖讓\",{\"1\":{\"7\":1}}],[\"但\",{\"1\":{\"31\":1}}],[\"但透過剪貼則可以造成不同環境的突兀感\",{\"1\":{\"21\":1}}],[\"但在邊界上往往還是難以有好的結果\",{\"1\":{\"20\":1}}],[\"但主要的問題來自於\",{\"1\":{\"20\":1}}],[\"但是實際上人數只會在那些開始以及結束的點被更新\",{\"1\":{\"56\":1}}],[\"但是會在不同時段\",{\"1\":{\"38\":1}}],[\"但是這種做法實際上效果很糟糕\",{\"1\":{\"23\":1}}],[\"但是並不全面\",{\"1\":{\"20\":1}}],[\"但是對於真實世界\",{\"1\":{\"16\":1}}],[\"但總結來說這次有還蠻有趣的體驗\",{\"1\":{\"11\":1}}],[\"但實際上有顏色才對\",{\"1\":{\"7\":1}}],[\"但基本上都不會太難\",{\"1\":{\"4\":1}}],[\"彩度跟亮度跟環境有些落差\",{\"1\":{\"7\":1}}],[\"此外\",{\"1\":{\"7\":1,\"10\":1}}],[\"份\",{\"1\":{\"7\":1}}],[\"55\",{\"1\":{\"33\":1}}],[\"53\",{\"1\":{\"33\":1}}],[\"59\",{\"1\":{\"9\":1}}],[\"5\",{\"1\":{\"7\":1,\"9\":2}}],[\"500分\",{\"1\":{\"2\":1}}],[\"處理上花了不少的時間\",{\"1\":{\"7\":1}}],[\"處理\",{\"0\":{\"7\":1},\"1\":{\"17\":1}}],[\"活下來\",{\"1\":{\"6\":1}}],[\"活動\",{\"1\":{\"3\":1}}],[\"活動參與\",{\"0\":{\"3\":1}}],[\"估計也是沒救\",{\"1\":{\"6\":1}}],[\"over\",{\"1\":{\"53\":1}}],[\"o\",{\"1\":{\"52\":2,\"53\":5,\"55\":2,\"56\":5}}],[\"otherwise\",{\"1\":{\"42\":1,\"53\":1}}],[\"olsson\",{\"1\":{\"21\":2}}],[\"or\",{\"0\":{\"20\":1},\"1\":{\"30\":1,\"42\":2}}],[\"on\",{\"1\":{\"15\":1,\"26\":2,\"34\":1,\"35\":1}}],[\"ocr\",{\"1\":{\"10\":1}}],[\"ouob\",{\"1\":{\"58\":1}}],[\"ouo\",{\"1\":{\"8\":1}}],[\"output\",{\"1\":{\"35\":1}}],[\"out\",{\"1\":{\"6\":1}}],[\"of\",{\"1\":{\"6\":1,\"15\":2}}],[\"丟進去訓練還是出現\",{\"1\":{\"6\":1}}],[\"模型會傾向回答\",{\"1\":{\"7\":1}}],[\"模型\",{\"1\":{\"6\":1}}],[\"看過一個\",{\"1\":{\"53\":1}}],[\"看能不能走到終點\",{\"1\":{\"42\":1}}],[\"看\",{\"1\":{\"20\":1}}],[\"看看結果如何\",{\"1\":{\"6\":1}}],[\"看圖說故事\",{\"1\":{\"5\":1}}],[\"都不太好\",{\"1\":{\"32\":1}}],[\"都是\",{\"1\":{\"31\":1}}],[\"都是虛擬世界當中的影像\",{\"1\":{\"27\":1}}],[\"都會對到\",{\"1\":{\"30\":1}}],[\"都會特別大\",{\"1\":{\"20\":1}}],[\"都可以使用\",{\"1\":{\"26\":1}}],[\"都被其他\",{\"1\":{\"23\":1}}],[\"都能夠透過\",{\"1\":{\"20\":1}}],[\"都完成了\",{\"1\":{\"10\":1}}],[\"都覺得很好理解\",{\"1\":{\"6\":1}}],[\"都相當地好吃\",{\"1\":{\"6\":1}}],[\"其中\",{\"1\":{\"41\":1}}],[\"其中一半的\",{\"1\":{\"21\":1}}],[\"其他絕大多都是\",{\"1\":{\"20\":1}}],[\"其他像是路燈\",{\"1\":{\"19\":1}}],[\"其他組的報告我們也可以透過實時的直播去看\",{\"1\":{\"10\":1}}],[\"其他的\",{\"1\":{\"7\":1,\"31\":1}}],[\"其他的大概就是\",{\"1\":{\"6\":1}}],[\"其實是哪一個人佔據了哪一個時段我們並不在乎\",{\"1\":{\"56\":1}}],[\"其實\",{\"1\":{\"10\":1}}],[\"其實不太好啦xd\",{\"1\":{\"9\":1}}],[\"其實讀\",{\"1\":{\"6\":1}}],[\"自己的\",{\"1\":{\"6\":1}}],[\"v\",{\"1\":{\"53\":13}}],[\"vector<block>\",{\"1\":{\"53\":1}}],[\"vector<int>\",{\"1\":{\"53\":2}}],[\"vector<vector<char>>\",{\"1\":{\"42\":1}}],[\"veg\",{\"1\":{\"31\":1}}],[\"valid\",{\"1\":{\"42\":1}}],[\"validation\",{\"1\":{\"8\":1,\"33\":4}}],[\"varied\",{\"1\":{\"35\":1}}],[\"volvo\",{\"1\":{\"15\":1}}],[\"v2\",{\"1\":{\"6\":1,\"26\":1,\"31\":1}}],[\"visited\",{\"1\":{\"42\":1}}],[\"vision\",{\"1\":{\"0\":1,\"1\":1,\"15\":1,\"35\":1},\"2\":{\"37\":1}}],[\"vis\",{\"1\":{\"42\":6}}],[\"virtual\",{\"1\":{\"30\":1}}],[\"viktor\",{\"1\":{\"21\":2}}],[\"via\",{\"0\":{\"14\":1,\"24\":1},\"1\":{\"35\":2}}],[\"vim\",{\"1\":{\"1\":1}}],[\"大概在幾天後就收到要填寫面試時間的通知信件\",{\"1\":{\"38\":1}}],[\"大概在今年的一月初投了履歷到\",{\"1\":{\"38\":1}}],[\"大概是人生第一次走進台積辦公室\",{\"1\":{\"4\":1}}],[\"大致上大家看過了幾個\",{\"1\":{\"6\":1}}],[\"用其他\",{\"1\":{\"6\":1}}],[\"去面對未知的題目跟挑戰\",{\"1\":{\"58\":1}}],[\"去確認\",{\"1\":{\"55\":1}}],[\"去看過每一個時間\",{\"1\":{\"55\":1}}],[\"去解\",{\"1\":{\"45\":1}}],[\"去解決也許會比\",{\"1\":{\"6\":1}}],[\"去解決這個問題\",{\"1\":{\"5\":1}}],[\"去訓練顯然很糟糕\",{\"1\":{\"31\":1,\"32\":1}}],[\"去\",{\"1\":{\"24\":1,\"31\":1}}],[\"去轉移出來\",{\"1\":{\"20\":1}}],[\"去判別現在給我的究竟是\",{\"1\":{\"19\":1}}],[\"去拉近\",{\"1\":{\"19\":1}}],[\"去調查看看有哪些其他還不錯的\",{\"1\":{\"6\":1}}],[\"覺得很開心\",{\"1\":{\"6\":1}}],[\"飲料\",{\"1\":{\"6\":1}}],[\"超級懷疑這個\",{\"1\":{\"7\":1}}],[\"超級舒服的人體工學椅\",{\"1\":{\"6\":1}}],[\"超大的雙螢幕\",{\"1\":{\"6\":1}}],[\"電動的升降桌\",{\"1\":{\"6\":1}}],[\"點心\",{\"1\":{\"6\":1}}],[\"點半再來報到\",{\"1\":{\"6\":1}}],[\"點就要回家\",{\"1\":{\"6\":1}}],[\"98\",{\"1\":{\"33\":1}}],[\"9400\",{\"1\":{\"30\":1}}],[\"9\",{\"1\":{\"6\":1}}],[\"隔天早上\",{\"1\":{\"6\":1}}],[\"68\",{\"1\":{\"33\":1}}],[\"6\",{\"1\":{\"6\":1}}],[\"600分\",{\"1\":{\"2\":1}}],[\"比賽會在正式開賽前一周公布題目\",{\"1\":{\"6\":1}}],[\"比賽過程\",{\"0\":{\"6\":1}}],[\"比賽題目\",{\"0\":{\"5\":1}}],[\"一場時間大概是\",{\"1\":{\"38\":1}}],[\"一樣去算每一個時間點的人數\",{\"1\":{\"56\":1}}],[\"一樣要到終點\",{\"1\":{\"44\":1}}],[\"一樣\",{\"1\":{\"26\":1}}],[\"一起\",{\"1\":{\"24\":1}}],[\"一個常見的問題是產出的結果通常會傾向去預測結果為常見的\",{\"1\":{\"20\":1}}],[\"一個簡單的方法是想辦法給這些\",{\"1\":{\"20\":1}}],[\"一個喜愛資訊領域的人\",{\"1\":{\"0\":1}}],[\"一開始進去到辦公室的感覺就很舒服\",{\"1\":{\"6\":1}}],[\"一些小細節上跟預期有些落差\",{\"1\":{\"58\":1}}],[\"一些\",{\"1\":{\"5\":1,\"20\":1}}],[\"運算及儲存資源\",{\"1\":{\"5\":1}}],[\"基本上就是從\",{\"1\":{\"21\":1}}],[\"基本上就是會有一些工地的照片\",{\"1\":{\"5\":1}}],[\"基本上他們期待我們會運用\",{\"1\":{\"5\":1}}],[\"寫了什麼\",{\"1\":{\"5\":1}}],[\"有沒有更好的解法呢\",{\"1\":{\"58\":1}}],[\"有沒有任何人違反了\",{\"1\":{\"5\":1}}],[\"有趣的是\",{\"1\":{\"38\":1}}],[\"有不少人最後給的結果之所以那麼好看是因為\",{\"1\":{\"33\":1}}],[\"有兩列分別表示\",{\"1\":{\"32\":1}}],[\"有點偏以及\",{\"1\":{\"31\":1}}],[\"有還不錯的\",{\"1\":{\"31\":1}}],[\"有一些常見的\",{\"1\":{\"27\":1}}],[\"有可能就被誤判成人行道\",{\"1\":{\"20\":1}}],[\"有部分的認知\",{\"1\":{\"20\":1}}],[\"有相當大的差異\",{\"1\":{\"19\":1}}],[\"有些是\",{\"1\":{\"32\":1}}],[\"有些\",{\"1\":{\"32\":1}}],[\"有些組別完成度很高\",{\"1\":{\"10\":1}}],[\"有些圖片上面會有\",{\"1\":{\"5\":1}}],[\"有多少人沒戴安全帽\",{\"1\":{\"5\":1}}],[\"有多少人有戴安全帽\",{\"1\":{\"5\":1}}],[\"希望暑假可以去累積累積經驗\",{\"1\":{\"38\":1}}],[\"希望我們可以去找到\",{\"1\":{\"5\":1}}],[\"希望透過這個\",{\"1\":{\"0\":1}}],[\"的面試往往要求的是跟面試官之間的互動\",{\"1\":{\"58\":1}}],[\"的人數有多少了\",{\"1\":{\"56\":1}}],[\"的人數是\",{\"1\":{\"55\":1}}],[\"的時間\",{\"1\":{\"56\":2}}],[\"的時間處理插入\",{\"1\":{\"53\":1}}],[\"的時間複雜度\",{\"1\":{\"53\":1}}],[\"的日期都列出來\",{\"1\":{\"54\":1}}],[\"的日期\",{\"1\":{\"51\":1}}],[\"的地圖\",{\"1\":{\"41\":1}}],[\"的版本\",{\"1\":{\"32\":1}}],[\"的版本是少了\",{\"1\":{\"30\":1}}],[\"的設定基本上跟\",{\"1\":{\"26\":1}}],[\"的設定上參考了許多過去的研究\",{\"1\":{\"26\":1}}],[\"的設計上也相當直覺\",{\"1\":{\"24\":1}}],[\"的結果要接近\",{\"1\":{\"24\":1}}],[\"的結果就當作是他的\",{\"1\":{\"20\":1}}],[\"的關聯性就能被連結起來\",{\"1\":{\"24\":1}}],[\"的核心做法是不單只是跟\",{\"1\":{\"24\":1}}],[\"的做法就是照著\",{\"1\":{\"23\":1}}],[\"的做法之所以能夠成功\",{\"1\":{\"19\":1}}],[\"的步驟\",{\"1\":{\"21\":1}}],[\"的一種\",{\"1\":{\"21\":1}}],[\"的技巧\",{\"1\":{\"21\":1}}],[\"的方法上雖然任何\",{\"1\":{\"26\":1}}],[\"的方法\",{\"1\":{\"23\":1}}],[\"的方法來降低這種問題\",{\"1\":{\"20\":1}}],[\"的方法解決了\",{\"1\":{\"20\":1}}],[\"的例子\",{\"1\":{\"20\":1}}],[\"的認識\",{\"1\":{\"20\":1}}],[\"的資料不存在任何\",{\"1\":{\"20\":1}}],[\"的資料上只有一些\",{\"1\":{\"20\":1}}],[\"的不同\",{\"1\":{\"19\":1}}],[\"的預測結果要接近\",{\"1\":{\"24\":1}}],[\"的預測結果\",{\"1\":{\"19\":1}}],[\"的狀況缺乏認知\",{\"1\":{\"17\":1}}],[\"的模型\",{\"1\":{\"31\":1}}],[\"的模型對於\",{\"1\":{\"17\":1}}],[\"的模型雖然有許多\",{\"1\":{\"17\":1}}],[\"的目標是把兩個不同分佈的\",{\"1\":{\"16\":1}}],[\"的比賽經驗很不錯\",{\"1\":{\"11\":1}}],[\"的輸入\",{\"1\":{\"10\":1}}],[\"的大家都很友善\",{\"1\":{\"10\":1}}],[\"的操作\",{\"1\":{\"8\":1}}],[\"的實用程度\",{\"1\":{\"7\":1}}],[\"的部分主要是參考各個\",{\"1\":{\"6\":1}}],[\"的研究\",{\"1\":{\"6\":1}}],[\"的回覆\",{\"1\":{\"6\":1}}],[\"的\",{\"1\":{\"6\":1,\"11\":1,\"19\":2,\"24\":1,\"26\":1,\"29\":1,\"30\":1,\"32\":1}}],[\"的敘述\",{\"1\":{\"5\":1}}],[\"的題目\",{\"1\":{\"5\":1}}],[\"的共同創辦人之一\",{\"1\":{\"0\":1}}],[\"dy\",{\"1\":{\"42\":2}}],[\"dx\",{\"1\":{\"42\":2}}],[\"doc\",{\"1\":{\"38\":1}}],[\"domain\",{\"0\":{\"14\":2,\"16\":1,\"19\":1,\"24\":2},\"1\":{\"16\":14,\"17\":5,\"19\":7,\"20\":10,\"23\":2,\"24\":6,\"31\":2,\"32\":1,\"35\":5},\"2\":{\"37\":1}}],[\"dt​\",{\"1\":{\"24\":1}}],[\"ds​\",{\"1\":{\"24\":1}}],[\"discriminator\",{\"1\":{\"19\":1}}],[\"distribution\",{\"1\":{\"17\":1}}],[\"disk\",{\"1\":{\"5\":1}}],[\"days\",{\"1\":{\"56\":1}}],[\"day\",{\"1\":{\"35\":2}}],[\"data\",{\"1\":{\"16\":1,\"17\":2,\"19\":2,\"20\":7,\"21\":2,\"35\":1}}],[\"dataset\",{\"0\":{\"27\":1},\"1\":{\"7\":3,\"23\":6}}],[\"datasets\",{\"0\":{\"7\":1},\"1\":{\"5\":1,\"7\":2}}],[\"dacs\",{\"0\":{\"14\":1,\"24\":1},\"1\":{\"19\":1,\"21\":1,\"24\":1,\"31\":1,\"32\":1,\"33\":3,\"35\":1}}],[\"dp\",{\"1\":{\"4\":1}}],[\"deeplab\",{\"1\":{\"26\":1,\"31\":1}}],[\"deep\",{\"1\":{\"0\":1}}],[\"前就已經做了不少\",{\"1\":{\"6\":1}}],[\"前面有一個預賽\",{\"1\":{\"4\":1}}],[\"前幾天去參加了\",{\"1\":{\"4\":1}}],[\"台積電的黑客松\",{\"1\":{\"4\":1}}],[\"臺灣好厲駭\",{\"1\":{\"3\":1}}],[\"i=v\",{\"1\":{\"53\":1}}],[\"i=0\",{\"1\":{\"42\":3,\"53\":2}}],[\"i+1\",{\"1\":{\"53\":4}}],[\"i++\",{\"1\":{\"42\":3,\"53\":3}}],[\"i<v\",{\"1\":{\"53\":3}}],[\"i<4\",{\"1\":{\"42\":1}}],[\"i<rows\",{\"1\":{\"42\":2}}],[\"implementation\",{\"1\":{\"42\":1}}],[\"images\",{\"1\":{\"28\":1,\"29\":1,\"30\":1}}],[\"imagenet\",{\"1\":{\"26\":1}}],[\"image\",{\"1\":{\"16\":2,\"17\":2,\"19\":2,\"20\":2,\"21\":5,\"23\":2,\"24\":2,\"28\":1,\"29\":1,\"30\":1,\"31\":2,\"32\":1}}],[\"i\",{\"1\":{\"42\":5,\"53\":9}}],[\"if\",{\"1\":{\"42\":5,\"50\":6,\"53\":3}}],[\"ide\",{\"1\":{\"38\":1}}],[\"issues\",{\"0\":{\"33\":1}}],[\"is\",{\"0\":{\"16\":1},\"1\":{\"42\":2}}],[\"isip\",{\"1\":{\"3\":1}}],[\"initialize\",{\"1\":{\"42\":1}}],[\"int>>\",{\"1\":{\"42\":1}}],[\"int>\",{\"1\":{\"42\":1}}],[\"int\",{\"1\":{\"42\":13,\"50\":4,\"51\":3,\"53\":3}}],[\"interview\",{\"0\":{\"38\":1},\"2\":{\"60\":1}}],[\"intern\",{\"0\":{\"38\":1}}],[\"introduce\",{\"1\":{\"34\":1}}],[\"in\",{\"1\":{\"34\":1,\"35\":1}}],[\"info\",{\"1\":{\"17\":1,\"19\":1,\"20\":4,\"23\":1,\"31\":1,\"32\":1,\"38\":1}}],[\"information\",{\"0\":{\"15\":1}}],[\"instructblip\",{\"1\":{\"6\":1}}],[\"it\",{\"1\":{\"11\":1}}],[\"ioicamp\",{\"1\":{\"3\":1}}],[\"ioncamp\",{\"1\":{\"3\":1}}],[\"奧義科技參訪\",{\"1\":{\"3\":1}}],[\"課程講師\",{\"1\":{\"3\":2}}],[\"索拉教育\",{\"1\":{\"3\":2}}],[\"班講師\",{\"1\":{\"3\":1}}],[\"資訊之芽\",{\"1\":{\"3\":1}}],[\"資訊安全\",{\"1\":{\"0\":1}}],[\"營長\",{\"1\":{\"3\":1}}],[\"講師\",{\"1\":{\"3\":1}}],[\"日語學習小組\",{\"1\":{\"3\":1}}],[\"日期\",{\"1\":{\"2\":1,\"3\":1}}],[\"成新的\",{\"1\":{\"23\":1}}],[\"成員\",{\"1\":{\"3\":2}}],[\"成績\",{\"1\":{\"2\":1}}],[\"機器學習讀書會\",{\"1\":{\"3\":1}}],[\"筆記\",{\"1\":{\"3\":3}}],[\"84\",{\"1\":{\"33\":1}}],[\"83\",{\"1\":{\"33\":1}}],[\"800\",{\"1\":{\"2\":1}}],[\"81\",{\"1\":{\"1\":1}}],[\"1\",{\"0\":{\"51\":1,\"52\":1,\"54\":1,\"55\":1},\"1\":{\"33\":1,\"42\":4,\"51\":1,\"52\":1,\"53\":6,\"56\":2}}],[\"17\",{\"1\":{\"33\":1}}],[\"13\",{\"1\":{\"30\":2,\"32\":2,\"33\":1}}],[\"13b\",{\"1\":{\"6\":1}}],[\"16\",{\"1\":{\"30\":1,\"32\":2,\"33\":1}}],[\"19\",{\"1\":{\"28\":1,\"29\":1}}],[\"128\",{\"1\":{\"2\":1}}],[\"101\",{\"1\":{\"31\":1}}],[\"100\",{\"1\":{\"5\":3}}],[\"100分\",{\"1\":{\"2\":3}}],[\"10\",{\"1\":{\"2\":1,\"33\":1,\"51\":1}}],[\"世界第三名\",{\"1\":{\"2\":1}}],[\"high\",{\"1\":{\"34\":1}}],[\"hitcon\",{\"1\":{\"3\":2}}],[\"hyperparameters\",{\"1\":{\"33\":1}}],[\"hyperparameter\",{\"1\":{\"26\":1}}],[\"h\",{\"1\":{\"24\":2}}],[\"hsuan\",{\"1\":{\"19\":2,\"26\":1}}],[\"hackday\",{\"1\":{\"6\":3}}],[\"hackdoor\",{\"1\":{\"3\":1}}],[\"human\",{\"1\":{\"2\":1}}],[\"hexo\",{\"1\":{\"1\":1}}],[\"金盾獎\",{\"1\":{\"2\":1}}],[\"全國第六名\",{\"1\":{\"2\":1}}],[\"35\",{\"1\":{\"33\":1}}],[\"314\",{\"1\":{\"2\":1}}],[\"300分\",{\"1\":{\"2\":1}}],[\"300\",{\"1\":{\"2\":1}}],[\"30\",{\"1\":{\"2\":1}}],[\"25\",{\"1\":{\"35\":1}}],[\"2975\",{\"1\":{\"28\":1}}],[\"2\",{\"0\":{\"53\":1,\"56\":1},\"1\":{\"9\":1}}],[\"24966\",{\"1\":{\"29\":1}}],[\"24\",{\"1\":{\"5\":1,\"35\":1}}],[\"2016\",{\"1\":{\"28\":1,\"30\":1}}],[\"2018\",{\"1\":{\"17\":1,\"19\":2,\"20\":1,\"26\":1}}],[\"2015\",{\"1\":{\"17\":1}}],[\"2019年03月\",{\"1\":{\"3\":1}}],[\"2019年08月\",{\"1\":{\"3\":2}}],[\"2019年06月\",{\"1\":{\"2\":1}}],[\"2019年07月\",{\"1\":{\"2\":1,\"3\":2}}],[\"2019年10月\",{\"1\":{\"2\":1}}],[\"2019年11月\",{\"1\":{\"2\":1,\"3\":1}}],[\"2019年12月\",{\"1\":{\"2\":1}}],[\"2019\",{\"1\":{\"2\":1,\"3\":3}}],[\"2021\",{\"1\":{\"15\":1,\"20\":1}}],[\"2021年\",{\"1\":{\"3\":1}}],[\"2023年09月\",{\"1\":{\"3\":1}}],[\"2023年04月\",{\"1\":{\"3\":1}}],[\"2020年\",{\"1\":{\"3\":1}}],[\"2020年08月\",{\"1\":{\"3\":2}}],[\"2020年09月\",{\"1\":{\"3\":1}}],[\"2020年01月\",{\"1\":{\"2\":1,\"3\":1}}],[\"2020年02月\",{\"1\":{\"2\":1}}],[\"2020年03月\",{\"1\":{\"2\":2}}],[\"2020年04月\",{\"1\":{\"2\":1}}],[\"2020年06月\",{\"1\":{\"2\":2}}],[\"2020年07月\",{\"1\":{\"2\":1,\"3\":2}}],[\"2020\",{\"1\":{\"2\":1,\"3\":3,\"15\":1,\"21\":2}}],[\"2022年08月\",{\"1\":{\"3\":1}}],[\"2022年07月\",{\"1\":{\"2\":1,\"3\":2}}],[\"2022年\",{\"1\":{\"3\":1}}],[\"2022年10月\",{\"1\":{\"2\":1,\"3\":1}}],[\"2024\",{\"0\":{\"4\":1,\"38\":1},\"1\":{\"2\":1,\"4\":1}}],[\"2024年01月\",{\"1\":{\"2\":1}}],[\"212\",{\"1\":{\"2\":1}}],[\"21\",{\"1\":{\"2\":1}}],[\"richter\",{\"1\":{\"29\":1}}],[\"rider\",{\"1\":{\"23\":1}}],[\"r\",{\"1\":{\"29\":1}}],[\"rows\",{\"1\":{\"42\":3}}],[\"road\",{\"1\":{\"23\":1,\"31\":1,\"32\":1,\"41\":1,\"42\":1}}],[\"round\",{\"1\":{\"2\":3}}],[\"ram\",{\"1\":{\"5\":2}}],[\"return\",{\"1\":{\"42\":2,\"50\":6,\"53\":3}}],[\"result\",{\"1\":{\"53\":1}}],[\"results\",{\"0\":{\"25\":1}}],[\"resnet\",{\"1\":{\"31\":1}}],[\"resnet101\",{\"1\":{\"26\":2}}],[\"research\",{\"1\":{\"6\":1}}],[\"related\",{\"0\":{\"18\":1}}],[\"release\",{\"1\":{\"15\":1}}],[\"reach\",{\"1\":{\"42\":1}}],[\"react\",{\"1\":{\"1\":1}}],[\"read\",{\"2\":{\"37\":1}}],[\"real\",{\"1\":{\"17\":1,\"19\":1,\"27\":1}}],[\"reverse\",{\"1\":{\"1\":1}}],[\"reinforcement\",{\"1\":{\"0\":1,\"1\":1}}],[\"germanros\",{\"1\":{\"30\":1}}],[\"generator\",{\"1\":{\"19\":1}}],[\"gta5\",{\"0\":{\"29\":1,\"31\":1},\"1\":{\"27\":2,\"29\":1,\"33\":1,\"34\":1}}],[\"gan\",{\"1\":{\"19\":1}}],[\"gb\",{\"1\":{\"5\":4}}],[\"gpu\",{\"1\":{\"5\":1}}],[\"gcp\",{\"1\":{\"5\":1}}],[\"graph\",{\"1\":{\"4\":1}}],[\"greedy\",{\"1\":{\"4\":1}}],[\"g\",{\"1\":{\"2\":1}}],[\"google\",{\"0\":{\"38\":1},\"1\":{\"2\":1,\"38\":3,\"58\":1},\"2\":{\"60\":1}}],[\"git\",{\"1\":{\"1\":1}}],[\"第二場面試小結\",{\"0\":{\"57\":1}}],[\"第二場面試\",{\"0\":{\"47\":1}}],[\"第一場面試下來自己覺得有盡可能去溝通\",{\"1\":{\"46\":1}}],[\"第一場面試小結\",{\"0\":{\"46\":1}}],[\"第一場面試\",{\"0\":{\"39\":1}}],[\"第八屆成功大學大學生活體驗營\",{\"1\":{\"3\":1}}],[\"第七屆高一生程式設計排名賽\",{\"1\":{\"2\":1}}],[\"第7名\",{\"1\":{\"2\":1}}],[\"第62名\",{\"1\":{\"2\":1}}],[\"第5695名\",{\"1\":{\"2\":1}}],[\"第2427名\",{\"1\":{\"2\":1}}],[\"第29755名\",{\"1\":{\"2\":1}}],[\"第22名\",{\"1\":{\"2\":1}}],[\"第96名\",{\"1\":{\"2\":1}}],[\"else\",{\"1\":{\"53\":3}}],[\"empty\",{\"1\":{\"42\":1}}],[\"emplace\",{\"1\":{\"42\":2,\"53\":3}}],[\"editor\",{\"1\":{\"38\":1}}],[\"everything\",{\"1\":{\"35\":1}}],[\"evaluation\",{\"0\":{\"33\":1}}],[\"early\",{\"1\":{\"33\":1}}],[\"enddat\",{\"1\":{\"56\":1}}],[\"endday+1\",{\"1\":{\"53\":1}}],[\"endday\",{\"1\":{\"51\":2,\"53\":9}}],[\"end\",{\"1\":{\"42\":2,\"53\":1,\"56\":1}}],[\"entropy\",{\"1\":{\"24\":1}}],[\"english\",{\"1\":{\"1\":1}}],[\"engineering\",{\"1\":{\"1\":1}}],[\"et\",{\"1\":{\"17\":2,\"19\":2,\"20\":2,\"21\":2,\"26\":1,\"28\":1,\"29\":1,\"30\":1}}],[\"exam\",{\"1\":{\"2\":1}}],[\"avaliable\",{\"1\":{\"53\":1}}],[\"abab\",{\"1\":{\"45\":1}}],[\"about\",{\"0\":{\"0\":1,\"33\":1}}],[\"ans\",{\"1\":{\"53\":5}}],[\"answer\",{\"1\":{\"42\":1,\"53\":2}}],[\"and\",{\"1\":{\"42\":1}}],[\"array\",{\"1\":{\"42\":1}}],[\"augmentation\",{\"1\":{\"35\":1}}],[\"augumentation\",{\"1\":{\"21\":2}}],[\"at\",{\"1\":{\"23\":2,\"24\":2,\"31\":2,\"32\":1}}],[\"add\",{\"1\":{\"53\":2}}],[\"adversarial\",{\"1\":{\"19\":1,\"20\":1,\"35\":1}}],[\"adapt\",{\"1\":{\"35\":1}}],[\"adaption\",{\"0\":{\"16\":1,\"24\":1},\"1\":{\"16\":2,\"20\":1},\"2\":{\"37\":1}}],[\"adaptation\",{\"0\":{\"14\":1},\"1\":{\"35\":4}}],[\"also\",{\"1\":{\"53\":1}}],[\"alignment\",{\"0\":{\"19\":1},\"1\":{\"19\":1}}],[\"al\",{\"1\":{\"17\":2,\"19\":2,\"20\":2,\"21\":2,\"23\":2,\"24\":2,\"26\":1,\"28\":1,\"29\":1,\"30\":1,\"31\":2,\"32\":1}}],[\"apply\",{\"1\":{\"16\":1,\"21\":2,\"34\":1}}],[\"applications\",{\"1\":{\"15\":1}}],[\"ai\",{\"1\":{\"5\":1}}],[\"ais3\",{\"1\":{\"2\":1,\"3\":2}}],[\"a\",{\"1\":{\"2\":1,\"21\":2,\"34\":1,\"41\":4,\"42\":2,\"44\":3,\"45\":4,\"50\":11}}],[\"網頁組第3名\",{\"1\":{\"2\":1}}],[\"網路管理等領域\",{\"1\":{\"0\":1}}],[\"青年黑克松\",{\"1\":{\"2\":1}}],[\"專題第三名\",{\"1\":{\"2\":1}}],[\"follow\",{\"0\":{\"43\":1,\"54\":1},\"1\":{\"46\":1}}],[\"for\",{\"1\":{\"2\":1,\"20\":1,\"35\":4,\"42\":6,\"53\":3}}],[\"false\",{\"1\":{\"42\":2}}],[\"fθ​\",{\"1\":{\"24\":3}}],[\"fence\",{\"1\":{\"30\":1}}],[\"feature\",{\"1\":{\"19\":1}}],[\"feedbacks\",{\"2\":{\"12\":1,\"59\":1}}],[\"feedback\",{\"1\":{\"11\":1}}],[\"framework\",{\"1\":{\"34\":1}}],[\"frameworks\",{\"1\":{\"1\":1}}],[\"front\",{\"1\":{\"42\":2}}],[\"frontend\",{\"1\":{\"10\":1}}],[\"from\",{\"1\":{\"16\":2,\"17\":2,\"19\":2,\"20\":2,\"21\":2,\"23\":2,\"24\":2,\"28\":1,\"29\":1,\"30\":1,\"31\":2,\"32\":1,\"42\":1}}],[\"flamingo\",{\"1\":{\"6\":1}}],[\"first\",{\"1\":{\"42\":2}}],[\"firstsecurity\",{\"1\":{\"3\":1}}],[\"findavaliable\",{\"1\":{\"53\":1}}],[\"findmedium\",{\"1\":{\"50\":1}}],[\"find\",{\"1\":{\"42\":1}}],[\"findexit\",{\"1\":{\"42\":1}}],[\"fintune\",{\"1\":{\"7\":1}}],[\"fine\",{\"1\":{\"6\":3,\"20\":1}}],[\"finetune\",{\"1\":{\"5\":1}}],[\"final\",{\"1\":{\"2\":1}}],[\"fml\",{\"1\":{\"2\":1}}],[\"梅竹黑客松\",{\"1\":{\"2\":1}}],[\"無\",{\"1\":{\"2\":1}}],[\"two\",{\"1\":{\"53\":1}}],[\"there\",{\"1\":{\"53\":1}}],[\"the\",{\"1\":{\"42\":1,\"53\":2}}],[\"true\",{\"1\":{\"42\":3}}],[\"tranheden\",{\"1\":{\"23\":2,\"24\":2,\"31\":2,\"32\":1}}],[\"training\",{\"0\":{\"20\":1},\"1\":{\"21\":2,\"28\":1,\"29\":1,\"30\":1,\"35\":1}}],[\"train\",{\"1\":{\"6\":1,\"31\":2}}],[\"tips\",{\"1\":{\"19\":1,\"23\":1,\"45\":1}}],[\"tsai\",{\"1\":{\"19\":2,\"26\":1}}],[\"tsmc\",{\"0\":{\"4\":1},\"1\":{\"2\":1,\"5\":1,\"10\":1,\"11\":2},\"2\":{\"13\":1}}],[\"target\",{\"1\":{\"16\":3,\"17\":1,\"19\":2,\"20\":7,\"23\":2,\"24\":4}}],[\"text\",{\"1\":{\"38\":1}}],[\"testset\",{\"1\":{\"33\":1}}],[\"technology\",{\"1\":{\"15\":1}}],[\"team\",{\"1\":{\"11\":1}}],[\"tuning\",{\"1\":{\"6\":1}}],[\"tune\",{\"1\":{\"6\":3,\"20\":1}}],[\"to\",{\"0\":{\"23\":1},\"1\":{\"23\":1,\"27\":1,\"33\":2,\"34\":2,\"35\":2,\"53\":3}}],[\"toi海選\",{\"1\":{\"2\":1}}],[\"toi校內賽\",{\"1\":{\"2\":1}}],[\"toi初選\",{\"1\":{\"2\":1}}],[\"toefl\",{\"1\":{\"1\":1}}],[\"心得\",{\"0\":{\"4\":1,\"38\":1},\"1\":{\"2\":2,\"3\":1}}],[\"競賽名稱\",{\"1\":{\"2\":1}}],[\"競賽成績\",{\"0\":{\"2\":1}}],[\"nm\",{\"1\":{\"52\":1,\"55\":1}}],[\"n\",{\"1\":{\"52\":1,\"53\":2,\"55\":1,\"56\":1}}],[\"ny\",{\"1\":{\"42\":8}}],[\"nx\",{\"1\":{\"42\":8}}],[\"n×m\",{\"1\":{\"41\":1}}],[\"next\",{\"1\":{\"53\":2}}],[\"needs\",{\"1\":{\"35\":1}}],[\"need\",{\"1\":{\"35\":1}}],[\"network\",{\"1\":{\"19\":2,\"24\":1,\"26\":1}}],[\"no\",{\"1\":{\"53\":1}}],[\"not\",{\"1\":{\"42\":1}}],[\"note\",{\"2\":{\"36\":1}}],[\"notes\",{\"1\":{\"35\":1}}],[\"none\",{\"1\":{\"7\":1}}],[\"naive\",{\"0\":{\"23\":1},\"1\":{\"23\":2}}],[\"native\",{\"1\":{\"1\":1}}],[\"nthu\",{\"1\":{\"3\":1}}],[\"npsc決賽\",{\"1\":{\"2\":1}}],[\"n1\",{\"1\":{\"1\":1}}],[\"j\",{\"1\":{\"42\":3}}],[\"j++\",{\"1\":{\"42\":2}}],[\"j<cols\",{\"1\":{\"42\":2}}],[\"j=0\",{\"1\":{\"42\":2}}],[\"jlpt\",{\"1\":{\"1\":1}}],[\"jam\",{\"1\":{\"2\":1}}],[\"japanese\",{\"1\":{\"1\":1}}],[\"javascripts\",{\"1\":{\"1\":1}}],[\"bfs\",{\"1\":{\"42\":3,\"45\":1}}],[\"be\",{\"1\":{\"53\":1}}],[\"begin\",{\"1\":{\"53\":1}}],[\"beat\",{\"1\":{\"34\":1}}],[\"best\",{\"1\":{\"33\":3}}],[\"benchmarks\",{\"1\":{\"27\":1}}],[\"build\",{\"1\":{\"31\":1}}],[\"bucket\",{\"1\":{\"5\":1}}],[\"binary\",{\"1\":{\"21\":1,\"26\":1}}],[\"b\",{\"1\":{\"21\":2,\"44\":3,\"45\":3,\"50\":11}}],[\"bool\",{\"1\":{\"42\":2,\"53\":1}}],[\"bonus\",{\"1\":{\"9\":1}}],[\"bot\",{\"1\":{\"1\":1}}],[\"back\",{\"1\":{\"53\":3}}],[\"backbone\",{\"1\":{\"26\":1,\"31\":1}}],[\"balanced\",{\"1\":{\"35\":1}}],[\"baseline\",{\"1\":{\"33\":1}}],[\"based\",{\"1\":{\"2\":1,\"26\":1,\"35\":1}}],[\"basic\",{\"0\":{\"15\":1}}],[\"bagging\",{\"1\":{\"8\":1}}],[\"blocks\",{\"1\":{\"53\":4}}],[\"block\",{\"1\":{\"51\":1,\"52\":3,\"53\":7,\"56\":1}}],[\"blog\",{\"1\":{\"0\":1}}],[\"blip\",{\"1\":{\"6\":1}}],[\"p\",{\"1\":{\"53\":4}}],[\"put\",{\"1\":{\"42\":1}}],[\"pair\",{\"1\":{\"42\":1}}],[\"pair<int\",{\"1\":{\"42\":1}}],[\"paper\",{\"1\":{\"6\":3,\"11\":1,\"20\":1,\"32\":1,\"33\":1},\"2\":{\"37\":1}}],[\"posts\",{\"0\":{\"61\":1}}],[\"pop\",{\"1\":{\"42\":1}}],[\"point\",{\"1\":{\"42\":5}}],[\"pole\",{\"1\":{\"30\":1}}],[\"perturbations\",{\"1\":{\"35\":1}}],[\"performance\",{\"1\":{\"31\":2,\"32\":1,\"34\":1}}],[\"personid\",{\"1\":{\"51\":1}}],[\"person\",{\"1\":{\"23\":1,\"31\":1}}],[\"pseudo\",{\"0\":{\"20\":1},\"1\":{\"20\":3,\"21\":1,\"23\":1,\"24\":1}}],[\"pixel\",{\"1\":{\"19\":1}}],[\"private\",{\"1\":{\"9\":1}}],[\"prediction\",{\"1\":{\"20\":2}}],[\"prefix\",{\"1\":{\"7\":2}}],[\"pretrained\",{\"1\":{\"5\":1,\"26\":1}}],[\"pre\",{\"1\":{\"2\":1}}],[\"proxy\",{\"1\":{\"6\":1}}],[\"project\",{\"1\":{\"2\":1}}],[\"programming\",{\"1\":{\"1\":2}}],[\"pytorch\",{\"1\":{\"1\":1}}],[\"python\",{\"1\":{\"1\":1,\"3\":1}}],[\"cmp\",{\"1\":{\"53\":2}}],[\"cityscape\",{\"1\":{\"34\":1}}],[\"cityscapes\",{\"0\":{\"28\":1,\"31\":1,\"32\":1},\"1\":{\"27\":3,\"29\":1,\"30\":1,\"33\":1}}],[\"city\",{\"1\":{\"30\":1}}],[\"cbst\",{\"1\":{\"20\":1}}],[\"classes\",{\"1\":{\"21\":1,\"28\":1,\"29\":2,\"30\":3,\"32\":1,\"33\":2}}],[\"classmix\",{\"1\":{\"21\":2,\"23\":1,\"24\":1,\"26\":1,\"34\":1,\"35\":1}}],[\"class\",{\"1\":{\"20\":2,\"23\":5,\"31\":2,\"32\":1,\"35\":1}}],[\"club\",{\"1\":{\"3\":1}}],[\"check\",{\"1\":{\"42\":4,\"53\":2,\"55\":1}}],[\"chiehchen\",{\"1\":{\"17\":1}}],[\"chalmers\",{\"1\":{\"15\":1}}],[\"cnn\",{\"1\":{\"17\":2}}],[\"cross\",{\"0\":{\"14\":1},\"1\":{\"24\":1,\"35\":1}}],[\"cryptography\",{\"1\":{\"1\":1}}],[\"cuda\",{\"1\":{\"6\":1}}],[\"cv\",{\"1\":{\"6\":1,\"16\":1}}],[\"cpu\",{\"1\":{\"5\":1}}],[\"can\",{\"1\":{\"53\":1}}],[\"cannot\",{\"1\":{\"42\":1}}],[\"case\",{\"1\":{\"45\":2}}],[\"car\",{\"1\":{\"31\":1}}],[\"cars\",{\"1\":{\"15\":1}}],[\"careerhack\",{\"0\":{\"4\":1},\"1\":{\"2\":1},\"2\":{\"13\":1}}],[\"camp\",{\"1\":{\"3\":2}}],[\"cs\",{\"1\":{\"3\":1}}],[\"cols\",{\"1\":{\"42\":3}}],[\"column\",{\"1\":{\"20\":1}}],[\"cordts\",{\"1\":{\"28\":1}}],[\"corss\",{\"0\":{\"24\":1}}],[\"continue\",{\"1\":{\"42\":3}}],[\"contribution\",{\"0\":{\"34\":1}}],[\"context\",{\"1\":{\"19\":1}}],[\"conflation\",{\"1\":{\"23\":1}}],[\"conference\",{\"1\":{\"15\":1}}],[\"competition\",{\"1\":{\"2\":1}}],[\"computer\",{\"1\":{\"0\":1,\"1\":1,\"15\":1,\"35\":1},\"2\":{\"37\":1}}],[\"code\",{\"1\":{\"2\":1,\"38\":1,\"58\":1}}],[\"c++\",{\"1\":{\"1\":1,\"3\":1}}],[\"c\",{\"1\":{\"1\":1,\"3\":1,\"50\":11}}],[\"s\",{\"1\":{\"53\":1}}],[\"should\",{\"1\":{\"53\":2}}],[\"shift\",{\"1\":{\"16\":3,\"20\":2,\"24\":1}}],[\"space\",{\"1\":{\"35\":1}}],[\"spatial\",{\"1\":{\"19\":2}}],[\"swe\",{\"0\":{\"38\":1},\"1\":{\"38\":1}}],[\"sw\",{\"1\":{\"31\":1,\"32\":1}}],[\"sky\",{\"1\":{\"31\":1}}],[\"skills\",{\"0\":{\"1\":1}}],[\"simplicity\",{\"1\":{\"42\":1}}],[\"simple\",{\"1\":{\"34\":1}}],[\"size\",{\"1\":{\"42\":2,\"53\":2}}],[\"sidewalk\",{\"1\":{\"23\":1}}],[\"sitcon\",{\"1\":{\"3\":2}}],[\"sb​\",{\"1\":{\"21\":2}}],[\"sa​\",{\"1\":{\"21\":3}}],[\"sampling\",{\"0\":{\"14\":1,\"24\":1},\"1\":{\"35\":1}}],[\"synthia\",{\"0\":{\"30\":1,\"32\":1},\"1\":{\"27\":2,\"32\":1,\"33\":1}}],[\"synthetic\",{\"1\":{\"27\":1,\"29\":1,\"30\":1}}],[\"synethic\",{\"1\":{\"16\":1,\"17\":1,\"19\":1}}],[\"sylwia\",{\"1\":{\"20\":1}}],[\"ssl\",{\"1\":{\"20\":1,\"34\":1}}],[\"supervise\",{\"1\":{\"20\":2}}],[\"supervised\",{\"1\":{\"20\":1,\"35\":5}}],[\"summer\",{\"1\":{\"3\":1}}],[\"summercamp\",{\"1\":{\"3\":1}}],[\"sota\",{\"1\":{\"34\":1}}],[\"some\",{\"0\":{\"33\":1}}],[\"source\",{\"1\":{\"16\":3,\"17\":1,\"19\":2,\"20\":2,\"24\":3,\"31\":3,\"32\":1}}],[\"sort\",{\"1\":{\"4\":1,\"53\":3,\"56\":1}}],[\"second\",{\"1\":{\"42\":2}}],[\"security\",{\"1\":{\"3\":1}}],[\"semi\",{\"1\":{\"20\":2,\"35\":5}}],[\"semantic\",{\"1\":{\"17\":1,\"19\":3,\"20\":1,\"21\":4,\"35\":4}}],[\"self\",{\"0\":{\"20\":1},\"1\":{\"35\":1}}],[\"segmentation\",{\"1\":{\"17\":1,\"19\":2,\"20\":1,\"21\":1,\"24\":1,\"26\":1,\"35\":5}}],[\"set\",{\"1\":{\"8\":1,\"9\":1,\"33\":5}}],[\"script\",{\"1\":{\"5\":1}}],[\"scist\",{\"1\":{\"0\":1,\"3\":1}}],[\"struct\",{\"1\":{\"51\":2,\"53\":2}}],[\"structured\",{\"1\":{\"35\":1}}],[\"strong\",{\"1\":{\"35\":1}}],[\"string\",{\"1\":{\"7\":2}}],[\"stop\",{\"1\":{\"33\":1}}],[\"storage\",{\"1\":{\"5\":1}}],[\"stephan\",{\"1\":{\"29\":1}}],[\"startday\",{\"1\":{\"51\":1,\"53\":14,\"56\":1}}],[\"start\",{\"1\":{\"2\":2,\"42\":8,\"56\":1}}],[\"領域的各種知識\",{\"1\":{\"0\":1}}],[\"領域發展\",{\"1\":{\"0\":1}}],[\"也頗主動去跟面試官互動\",{\"1\":{\"57\":1}}],[\"也跟最後評估的\",{\"1\":{\"33\":1}}],[\"也就是說\",{\"1\":{\"44\":1}}],[\"也就是說我們對於\",{\"1\":{\"20\":1}}],[\"也就很難往下一步去發展\",{\"1\":{\"11\":1}}],[\"也獲得不錯的成果\",{\"1\":{\"17\":1}}],[\"也很期待未來也還有機會可以繼續了解和開發\",{\"1\":{\"11\":1}}],[\"也能感受到他們對我們的提問的重視\",{\"1\":{\"11\":1}}],[\"也讓我認識到\",{\"1\":{\"11\":1}}],[\"也可以盡可能至少在\",{\"1\":{\"8\":1}}],[\"也寫了一個評分程式去評估好壞\",{\"1\":{\"7\":1}}],[\"也想說難得有不錯的運算資源\",{\"1\":{\"6\":1}}],[\"也有可能很大\",{\"1\":{\"53\":1}}],[\"也有先好好確認過題目的條件\",{\"1\":{\"46\":1}}],[\"也有先提供了一些資源\",{\"1\":{\"5\":1}}],[\"也有提供一些線上的資源協助你去了解如何準備面試\",{\"1\":{\"38\":1}}],[\"也有部分是源自於這樣的相似性帶來的好處\",{\"1\":{\"19\":1}}],[\"也有人套了\",{\"1\":{\"10\":1}}],[\"也有聽說有部分的組別\",{\"1\":{\"6\":1}}],[\"也開放資源\",{\"1\":{\"6\":1}}],[\"也歡迎一起來討論\",{\"1\":{\"0\":1}}],[\"也是有些包含浮水印\",{\"1\":{\"7\":1}}],[\"也是頗有趣\",{\"1\":{\"6\":1}}],[\"也是\",{\"1\":{\"0\":1}}],[\"紀錄學習的點滴\",{\"1\":{\"0\":1}}],[\"m+mlogm+m+n\",{\"1\":{\"56\":1}}],[\"more\",{\"1\":{\"53\":1}}],[\"model\",{\"1\":{\"0\":1,\"5\":1,\"6\":1,\"20\":1,\"31\":1}}],[\"mscoco\",{\"1\":{\"26\":1}}],[\"m\",{\"1\":{\"21\":3,\"52\":2,\"53\":1,\"55\":1,\"56\":2}}],[\"miou\",{\"1\":{\"32\":1}}],[\"mix\",{\"1\":{\"24\":1}}],[\"mixup\",{\"1\":{\"21\":1}}],[\"mixing\",{\"0\":{\"21\":1,\"23\":1},\"1\":{\"21\":3,\"23\":2,\"24\":2,\"26\":2}}],[\"mixed\",{\"0\":{\"14\":1,\"24\":1},\"1\":{\"23\":1,\"35\":1}}],[\"minigpt4\",{\"1\":{\"6\":2}}],[\"miscellaneous\",{\"1\":{\"1\":1}}],[\"my\",{\"1\":{\"3\":1}}],[\"myfirstctf\",{\"1\":{\"2\":1}}],[\"make\",{\"1\":{\"42\":1}}],[\"marius\",{\"1\":{\"28\":1}}],[\"markdown\",{\"1\":{\"1\":1}}],[\"mask\",{\"1\":{\"21\":3,\"26\":1}}],[\"majchrowska\",{\"1\":{\"20\":1}}],[\"map\",{\"1\":{\"19\":1,\"21\":3}}],[\"maps\",{\"1\":{\"19\":2,\"42\":6}}],[\"mandarin\",{\"1\":{\"1\":1}}],[\"machine\",{\"1\":{\"1\":1,\"2\":1,\"3\":1}}],[\"mlogm+n+m\",{\"1\":{\"53\":1}}],[\"mlogm\",{\"1\":{\"53\":1,\"56\":1}}],[\"ml\",{\"1\":{\"0\":1}}],[\"merge\",{\"1\":{\"53\":3}}],[\"method\",{\"1\":{\"34\":1}}],[\"methodology\",{\"0\":{\"22\":1}}],[\"medium\",{\"1\":{\"16\":2}}],[\"memory\",{\"1\":{\"6\":1}}],[\"message\",{\"1\":{\"5\":3}}],[\"me\",{\"0\":{\"0\":1}}],[\"l\",{\"1\":{\"24\":1}}],[\"look\",{\"1\":{\"53\":1}}],[\"loss\",{\"1\":{\"24\":1}}],[\"local\",{\"1\":{\"19\":1}}],[\"lebel\",{\"1\":{\"24\":1}}],[\"level\",{\"1\":{\"19\":3}}],[\"learning\",{\"1\":{\"0\":2,\"1\":2,\"2\":1,\"3\":1,\"19\":1,\"20\":3,\"35\":5}}],[\"liang\",{\"1\":{\"17\":1}}],[\"line\",{\"1\":{\"1\":1}}],[\"llava\",{\"1\":{\"5\":2,\"6\":2}}],[\"llm\",{\"1\":{\"5\":1,\"6\":6,\"7\":1,\"10\":1,\"11\":2}}],[\"l4\",{\"1\":{\"5\":1}}],[\"layout\",{\"1\":{\"19\":2}}],[\"labelled\",{\"1\":{\"23\":1}}],[\"labelling\",{\"0\":{\"20\":1},\"1\":{\"21\":1,\"23\":1}}],[\"labeling\",{\"1\":{\"20\":1}}],[\"labeled\",{\"1\":{\"20\":2}}],[\"label\",{\"1\":{\"16\":2,\"20\":4,\"24\":1}}],[\"languagues\",{\"1\":{\"1\":1}}],[\"languages\",{\"1\":{\"1\":1}}],[\"language\",{\"1\":{\"0\":1}}],[\"large\",{\"1\":{\"0\":1}}],[\"關注的主題包含\",{\"1\":{\"0\":1}}],[\"目前正在朝向\",{\"1\":{\"0\":1}}],[\"目前就讀於清華大學資訊工程學系\",{\"1\":{\"0\":1}}],[\"高中接觸了演算法\",{\"1\":{\"0\":1}}],[\"本名林禾堃\",{\"1\":{\"0\":1}}]],\"serializationVersion\":2}}")).map(([e,t])=>[e,zt(t,{fields:["h","t","c"],storeFields:["h","t","c"]})]));self.onmessage=({data:{type:e="all",query:t,locale:s,options:n}})=>{e==="suggest"?self.postMessage(st(t,v[s],n)):e==="search"?self.postMessage(et(t,v[s],n)):self.postMessage({suggestions:st(t,v[s],n),results:et(t,v[s],n)})};
//# sourceMappingURL=index.js.map
