const e=JSON.parse('{"key":"v-073f61cf","path":"/posts/Dropout.html","title":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting","lang":"en-US","frontmatter":{"date":"2024-03-17T00:00:00.000Z","category":["Note"],"tag":["Paper Read","Regularization","JMLR"],"author":"Koios","description":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting Basic Information Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov @ Toronto University 2014 JMLR 問題描述 在近年來發現到 Neural Network 參數越多就有越強大的表達能力，並且通常會有更好的表現。不過隨著參數量的上升，我們也發現到模型越來越會傾向於 Overfitting。","head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/PaperBlog/posts/Dropout.html"}],["meta",{"property":"og:site_name","content":"Paper Blog"}],["meta",{"property":"og:title","content":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting"}],["meta",{"property":"og:description","content":"Dropout: A Simple Way to Prevent Neural Networks from Overfitting Basic Information Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov @ Toronto University 2014 JMLR 問題描述 在近年來發現到 Neural Network 參數越多就有越強大的表達能力，並且通常會有更好的表現。不過隨著參數量的上升，我們也發現到模型越來越會傾向於 Overfitting。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-03-17T09:45:46.000Z"}],["meta",{"property":"article:author","content":"Koios"}],["meta",{"property":"article:tag","content":"Paper Read"}],["meta",{"property":"article:tag","content":"Regularization"}],["meta",{"property":"article:tag","content":"JMLR"}],["meta",{"property":"article:published_time","content":"2024-03-17T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-03-17T09:45:46.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-03-17T00:00:00.000Z\\",\\"dateModified\\":\\"2024-03-17T09:45:46.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Koios\\"}]}"]]},"headers":[{"level":2,"title":"Basic Information","slug":"basic-information","link":"#basic-information","children":[]},{"level":2,"title":"問題描述","slug":"問題描述","link":"#問題描述","children":[]},{"level":2,"title":"Related Works","slug":"related-works","link":"#related-works","children":[{"level":3,"title":"Denoising Autoencoders (DAEs)","slug":"denoising-autoencoders-daes","link":"#denoising-autoencoders-daes","children":[]}]},{"level":2,"title":"Methodology","slug":"methodology","link":"#methodology","children":[{"level":3,"title":"Overview","slug":"overview","link":"#overview","children":[]},{"level":3,"title":"Model Description","slug":"model-description","link":"#model-description","children":[]},{"level":3,"title":"Learning Dropout Nets","slug":"learning-dropout-nets","link":"#learning-dropout-nets","children":[]}]},{"level":2,"title":"Results","slug":"results","link":"#results","children":[{"level":3,"title":"Datasets","slug":"datasets","link":"#datasets","children":[]},{"level":3,"title":"Result on Image Datasets","slug":"result-on-image-datasets","link":"#result-on-image-datasets","children":[]},{"level":3,"title":"Result on Speech Recognition","slug":"result-on-speech-recognition","link":"#result-on-speech-recognition","children":[]},{"level":3,"title":"Result on Text Dataset","slug":"result-on-text-dataset","link":"#result-on-text-dataset","children":[]},{"level":3,"title":"How Dropout Effect Network","slug":"how-dropout-effect-network","link":"#how-dropout-effect-network","children":[]},{"level":3,"title":"Hyperparameter","slug":"hyperparameter","link":"#hyperparameter","children":[]},{"level":3,"title":"Effect of Data Size","slug":"effect-of-data-size","link":"#effect-of-data-size","children":[]}]},{"level":2,"title":"Contribution","slug":"contribution","link":"#contribution","children":[]},{"level":2,"title":"值得一看的文章們","slug":"值得一看的文章們","link":"#值得一看的文章們","children":[]}],"git":{"createdTime":1710668746000,"updatedTime":1710668746000,"contributors":[{"name":"Koios","email":"ken1357924681010@gmail.com","commits":1}]},"readingTime":{"minutes":9.58,"words":2874},"filePathRelative":"posts/Dropout.md","localizedDate":"March 17, 2024","excerpt":"<h1> Dropout: A Simple Way to Prevent Neural Networks from Overfitting</h1>\\n<h2> Basic Information</h2>\\n<ul>\\n<li>Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov @ Toronto University</li>\\n<li>2014 JMLR</li>\\n</ul>\\n<h2> 問題描述</h2>\\n<p>在近年來發現到 Neural Network 參數越多就有越強大的表達能力，並且通常會有更好的表現。不過隨著參數量的上升，我們也發現到模型越來越會傾向於 Overfitting。</p>","autoDesc":true}');export{e as data};
